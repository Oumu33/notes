# 集群管理
# 集群状态监控
## 查看集群总体状态
```bash
root@ceph-1:~# ceph -s
  cluster:
    id:     402d9800-afef-11ef-92d7-9fbbd69ceccd # 集群的唯一标识符，用于标记 Ceph 集群。这个值是全局唯一的 UUID。
    health: HEALTH_OK #  当前集群的健康状态

  services:
    mon: 3 daemons, quorum ceph-1,ceph-3,ceph-2 (age 34m) #  集群中有 3 个 Monitor 节点
    mgr: ceph-1.cuuabg(active, since 34m), standbys: ceph-3.uhtqme # ceph-1 是当前活跃的 Manager 节点，标识符为 cuuabg，ceph-3 是备用 Manager 节点，标识符为 uhtqme
    osd: 3 osds: 3 up (since 34m), 3 in (since 22h) #  集群中共有 3 个 OSD 守护进程。

  data:
    pools:   2 pools, 33 pgs # 集群中创建了 2 个数据存储池, 33 个 Placement Groups（PG），即数据分片的数量
    objects: 2 objects, 449 KiB # 集群中存储了 2 个对象（对象是 Ceph 中的最小数据存储单位）,存储的对象总大小为 449 KiB
    usage:   222 MiB used, 150 GiB / 150 GiB avail # OSD 上已使用的磁盘空间为 222 MiB，总容量为 150 GiB，其中 150 GiB 可用
    pgs:     33 active+clean #  33 个 PG 都处于 active+clean 状态：active: PG 可用且正在服务。clean: PG 数据一致且完整，没有任何副本丢失或需要恢复。
```

## 查看详细健康信息
```bash
root@ceph-1:~# ceph health detail
HEALTH_WARN clock skew detected on mon.ceph-3, mon.ceph-2
[WRN] MON_CLOCK_SKEW: clock skew detected on mon.ceph-3, mon.ceph-2
    mon.ceph-3 clock skew 0.0900462s > max 0.05s (latency 0.00099869s)
    mon.ceph-2 clock skew 0.0744678s > max 0.05s (latency 0.00100641s)
```

+ 提供健康警告的具体细节，例如节点时钟不同步。

## 查看存储状态
```bash
root@ceph-1:~# ceph df
--- RAW STORAGE ---
CLASS     SIZE    AVAIL     USED  RAW USED  %RAW USED
hdd    150 GiB  150 GiB  222 MiB   222 MiB       0.14
TOTAL  150 GiB  150 GiB  222 MiB   222 MiB       0.14

--- POOLS ---
POOL    ID  PGS   STORED  OBJECTS     USED  %USED  MAX AVAIL
.mgr     1    1  449 KiB        2  1.3 MiB      0     47 GiB
mypool   2   32      0 B        0      0 B      0     47 GiB
```

## 查看监控节点状态
```bash
root@ceph-1:~# ceph mon stat
e3: 3 mons at {ceph-1=[v2:192.168.10.91:3300/0,v1:192.168.10.91:6789/0],ceph-2=[v2:192.168.10.92:3300/0,v1:192.168.10.92:6789/0],ceph-3=[v2:192.168.10.93:3300/0,v1:192.168.10.93:6789/0]} removed_ranks: {} disallowed_leaders: {}, election epoch 24, leader 0 ceph-1, quorum 0,1,2 ceph-1,ceph-3,ceph-2
```

+ 显示当前监控节点的数量和状态。

## 查看 OSD 使用情况
```bash
root@ceph-1:~# ceph osd df
ID  CLASS  WEIGHT   REWEIGHT  SIZE     RAW USE  DATA     OMAP    META     AVAIL    %USE  VAR   PGS  STATUS
 0    hdd  0.04880   1.00000   50 GiB   74 MiB  4.2 MiB   4 KiB   70 MiB   50 GiB  0.14  1.00   33      up
 1    hdd  0.04880   1.00000   50 GiB   74 MiB  4.2 MiB   4 KiB   70 MiB   50 GiB  0.14  1.00   33      up
 2    hdd  0.04880   1.00000   50 GiB   74 MiB  4.2 MiB   4 KiB   70 MiB   50 GiB  0.14  1.00   33      up
                       TOTAL  150 GiB  222 MiB   13 MiB  13 KiB  210 MiB  150 GiB  0.14
MIN/MAX VAR: 1.00/1.00  STDDEV: 0
```

+ 显示每个 OSD 的存储容量和使用率。

## 检查池的状态
```bash
root@ceph-1:~# ceph osd pool stats
pool .mgr id 1
  nothing is going on

pool mypool id 2
  nothing is going on
```

+ 显示每个池的 I/O 性能和状态。

## 显示 CRUSH 映射状态
```bash
root@ceph-1:~# ceph osd tree
ID  CLASS  WEIGHT   TYPE NAME        STATUS  REWEIGHT  PRI-AFF
-1         0.14639  root default
-3         0.04880      host ceph-1
 0    hdd  0.04880          osd.0        up   1.00000  1.00000
-5         0.04880      host ceph-2
 1    hdd  0.04880          osd.1        up   1.00000  1.00000
-7         0.04880      host ceph-3
 2    hdd  0.04880          osd.2        up   1.00000  1.00000
```

+ 以树状结构显示 OSD 的分布及其在 CRUSH 映射中的位置。

# 事件与日志查看
## 检查集群状态事件
```plain
ceph -w
```

+ 实时监控集群事件。

## 检查集群归档事件
+  查找最近崩溃的信息  

```plain
ceph crash ls
```

+ 查找奔溃信息详情

```plain
ceph crash info <CRASH_ID>
```

+  归档所有崩溃记录  

```plain
ceph crash archive-all
```

## 检查 Ceph 配置
```bash
root@ceph-1:~# ceph config dump
WHO     MASK  LEVEL     OPTION                                 VALUE                                                                                      RO
global        advanced  cluster_network                        192.168.10.0/24                                                                            *
global        basic     container_image                        quay.io/ceph/ceph@sha256:6ac7f923aa1d23b43248ce0ddec7e1388855ee3d00813b52c3172b0b23b37906  *
mon           advanced  auth_allow_insecure_global_id_reclaim  false
mon           advanced  public_network                         192.168.10.0/24                                                                            *
mgr           advanced  mgr/cephadm/container_init             True                                                                                       *
mgr           advanced  mgr/cephadm/migration_current          6                                                                                          *
mgr           advanced  mgr/dashboard/ALERTMANAGER_API_HOST    http://ceph-1:9093                                                                         *
mgr           advanced  mgr/dashboard/GRAFANA_API_SSL_VERIFY   false                                                                                      *
mgr           advanced  mgr/dashboard/GRAFANA_API_URL          https://ceph-1:3000                                                                        *
mgr           advanced  mgr/dashboard/PROMETHEUS_API_HOST      http://ceph-1:9095                                                                         *
mgr           advanced  mgr/dashboard/ssl_server_port          8443                                                                                       *
mgr           advanced  mgr/orchestrator/orchestrator          cephadm
mgr           advanced  mgr/telemetry/enabled                  true                                                                                       *
osd           advanced  osd_memory_target_autotune             true
```

## 查看守护进程状态
```bash
root@ceph-1:~# ceph orch ps
NAME                  HOST    PORTS             STATUS        REFRESHED  AGE  MEM USE  MEM LIM  VERSION    IMAGE ID      CONTAINER ID  
alertmanager.ceph-1   ceph-1  *:9093,9094       error            5m ago   2d        -        -  <unknown>  <unknown>     <unknown>
ceph-exporter.ceph-1  ceph-1                    running (6m)     5m ago   2d    9.85M        -  18.2.4     2bc0b0f4375d  ee09de48a195
ceph-exporter.ceph-2  ceph-2                    running (6m)     6m ago   2d    13.5M        -  18.2.4     2bc0b0f4375d  0f0512332580
ceph-exporter.ceph-3  ceph-3                    running (6m)     6m ago   2d    9528k        -  18.2.4     2bc0b0f4375d  bf99027af1ca
crash.ceph-1          ceph-1                    running (6m)     5m ago   2d    10.8M        -  18.2.4     2bc0b0f4375d  6a97f6e7611e
crash.ceph-2          ceph-2                    running (6m)     6m ago   2d    16.5M        -  18.2.4     2bc0b0f4375d  48dda354ab9f
crash.ceph-3          ceph-3                    running (6m)     6m ago   2d    14.0M        -  18.2.4     2bc0b0f4375d  310d2b7cae45
grafana.ceph-1        ceph-1  *:3000            running (6m)     5m ago   2d     120M        -  9.4.7      954c08fa6188  dd5217fe82cf
mgr.ceph-1.xklufv     ceph-1  *:9283,8765,8443  running (6m)     5m ago   2d     466M        -  18.2.4     2bc0b0f4375d  b844f7cdcd17
mgr.ceph-3.yjdakp     ceph-3  *:8443,9283,8765  running (6m)     6m ago   2d     488M        -  18.2.4     2bc0b0f4375d  058adef5618a
mon.ceph-1            ceph-1                    running          5m ago   2d        -    2048M  <unknown>  <unknown>     <unknown>
mon.ceph-2            ceph-2                    running (6m)     6m ago   2d    41.0M    2048M  18.2.4     2bc0b0f4375d  57158cb4c5a1
mon.ceph-3            ceph-3                    running (6m)     6m ago   2d    30.5M    2048M  18.2.4     2bc0b0f4375d  ae1e928e3dff
node-exporter.ceph-1  ceph-1  *:9100            error            5m ago   2d        -        -  <unknown>  <unknown>     <unknown>
node-exporter.ceph-2  ceph-2  *:9100            running (6m)     6m ago   2d    9.96M        -  1.5.0      0da6a335fe13  0080b5c3272d
node-exporter.ceph-3  ceph-3  *:9100            unknown          6m ago   2d        -        -  <unknown>  <unknown>     <unknown>
osd.0                 ceph-1                    running (6m)     5m ago   2d    70.2M    4096M  18.2.4     2bc0b0f4375d  e884353bde88
osd.1                 ceph-2                    running (6m)     6m ago   2d    67.6M    4096M  18.2.4     2bc0b0f4375d  98503bbfba86
osd.2                 ceph-3                    running (6m)     6m ago   2d    70.2M    4096M  18.2.4     2bc0b0f4375d  3c611e82107b
prometheus.ceph-1     ceph-1  *:9095            unknown          5m ago   2d        -        -  <unknown>  <unknown>     <unknown>
```

## 重启守护进程
查看哪些 `cephadm` 守护进程失败，然后尝试重启或修复它们，可以使用以下命令重启：

```bash
ceph orch restart <daemon_name>
```

或者，如果守护进程故障严重，可能需要重新部署这些守护进程。

## 本地日志查看
```bash
root@ceph-1:/var/log/ceph/8e04b1c8-ad9f-11ef-a78d-07c031166f43# ls
ceph-client.ceph-exporter.ceph-1.log  ceph-osd.0.log  ceph-volume.log
```

## 集群日志查看
```plain
ceph log last <component>
```

+ 示例，查看最近 1 千条日志：

```plain
root@ceph-1:~# ceph log last 1000
```

## 服务日志查看
```plain
root@ceph-1:~# journalctl -u ceph-402d9800-afef-11ef-92d7-9fbbd69ceccd@osd.0.service
```

# Map 映射
## <font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"></font>查看当前的 OSD 映射
<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">显示 Ceph 集群中所有 OSD 的映射，能够帮助你了解哪些 OSD 处于活跃状态，哪些是下线的。</font>

```plain
ceph osd tree
```

## <font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"></font>查看 Ceph OSD Map
<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">通过以下命令查看集群中的 OSD 映射信息，它会列出 OSD 的具体状态、ID 以及与存储池（pool）相关的映射。</font>

```plain
ceph osd dump
```

## <font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"></font>查看 PG 映射信息
<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">查看 PG（Placement Group）的详细映射信息，检查每个 PG 所在的 OSD 和副本信息。非常有助于排查数据丢失或 PG 映射问题。</font>

```plain
ceph pg dump
```

## <font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"></font>查看 CRUSH 映射
<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">CRUSH（Controlled Replication Under Scalable Hashing）是 Ceph 用于数据分布的算法。使用 </font>`<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">crush</font>`<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"> 映射来查看集群的存储设备如何进行数据分布。</font>

```plain
ceph osd crush dump
```

<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">该命令会显示 CRUSH 映射的详细信息，包括设备权重、规则、桶（bucket）等。</font>

## 查看集群的 MON 映射
<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">显示监视器的映射信息，这对于查看当前监视器的状态和配置很有用。</font>

```plain
ceph mon stat
```

## <font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"></font>查看池的映射信息
<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">如果你想查看某个特定存储池的映射信息，可以使用以下命令：</font>

```plain
ceph osd pool stats <pool_name>
```

## <font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"></font>查看集群的 MDS 映射
<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">Ceph 的 MDS（Metadata Server）用于处理 CephFS 文件系统的元数据。查看 MDS 的映射情况有助于了解元数据分布。</font>

```plain
ceph mds stat
```

## 查看集群的 OSD Map
`<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">ceph osd map</font>`<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);"> 命令提供了有关 OSD 的映射信息。你可以通过它来查看 OSD 是否成功地与某个 PG 或对象进行映射。</font>

```plain
ceph osd map <pg_id> <object_id>
```

<font style="color:rgb(0, 0, 0);background-color:rgb(238, 238, 238);">用于查看某个对象在某个 PG 中的具体 OSD 映射。</font>


