# 大模型架构

> 分类: AIOPS > 大模型基础
> 更新时间: 2026-01-10T23:34:34.926053+08:00

---

# Transformer 架构
参考文档：[https://www.runoob.com/nlp/transformer-architecture.html](https://www.runoob.com/nlp/transformer-architecture.html)

公众号文章：[https://mp.weixin.qq.com/s/bQE58LII4nXvO2hkjlYvsw](https://mp.weixin.qq.com/s/bQE58LII4nXvO2hkjlYvsw)

# <font style="color:rgb(0, 0, 0);background-color:rgb(250, 252, 253);">BERT</font> 模型
参考文档：[https://www.runoob.com/nlp/bert-encoder.html](https://www.runoob.com/nlp/bert-encoder.html)

公众号文章：[https://mp.weixin.qq.com/s/0wA8BMGrJxWYDu0HAl7Bhg](https://mp.weixin.qq.com/s/0wA8BMGrJxWYDu0HAl7Bhg)

# GPT 架构
参考文档：[https://www.runoob.com/nlp/generative-pre-trained-transformer.html](https://www.runoob.com/nlp/generative-pre-trained-transformer.html)

公众号文章：[https://mp.weixin.qq.com/s/S-gdaAn3izW2NC70-MZjuw](https://mp.weixin.qq.com/s/S-gdaAn3izW2NC70-MZjuw)

# MoE 模型
公众号文章：[https://mp.weixin.qq.com/s/I9L3Ldw6s5Ui3vbPX5g8mw](https://mp.weixin.qq.com/s/I9L3Ldw6s5Ui3vbPX5g8mw)

