# AI与大模型介绍

> 来源: AIOPS
> 创建时间: 2025-07-17T15:04:59+08:00
> 更新时间: 2026-01-11T09:43:55.797412+08:00
> 阅读量: 3629 | 点赞: 5

---

# AI 的总体发展历程
| 阶段 | 时间 | 核心技术 | 特点 |
| --- | --- | --- | --- |
| 早期 AI（符号主义） | 1950s–1980s | 规则系统、专家系统 | 人工编规则，推理逻辑强，通用性差 |
| 统计机器学习 | 1980s–2010s | SVM、KNN、决策树、Naive Bayes | 模型从数据中学习，泛化更强 |
| 深度学习崛起 | 2012–至今 | CNN、RNN、Transformer | 端到端、自动提特征，突破图像/语音/NLP |
| 大模型时代 | 2020–至今 | GPT、BERT、Diffusion、多模态 | 预训练+微调，通用智能趋势 |


# 从机器学习到深度学习 
## 机器学习（Machine Learning）
机器学习是**从数据中学习模型**的技术。典型流程：

+ 人工提取特征（Feature Engineering）
+ 输入特征给模型（如 SVM、逻辑回归、随机森林）
+ 模型学习输入与输出的映射关系

示例模型：

+ 监督学习：KNN、SVM、决策树、随机森林
+ 无监督学习：K-Means、PCA
+ 强化学习：Q-Learning

局限：

+ 需要手工设计特征（如图像的边缘、颜色直方图）
+ 对复杂结构数据（图像、语音、语言）学习能力差

## 深度学习（Deep Learning）
深度学习是**以神经网络为核心**的学习方式，它能够**自动从原始数据中提取特征**。

技术转折点：

+ **2012 年 AlexNet 赢得 ImageNet 图像识别比赛**，误差骤降，深度学习进入主流
+ 利用 GPU、大数据训练多层神经网络
+ 后续演变出 CNN、RNN、LSTM、Transformer 等模型

核心优势：

+ 不再依赖人工特征设计
+ 能直接处理图像、语音、文本等原始数据
+ 越大越强，规模化带来性能跃迁

## 机器学习与深度学习对比
| 项目 | 机器学习（ML） | 深度学习（DL） |
| --- | --- | --- |
| 特征提取 | 人工提取 | 自动学习 |
| 模型复杂度 | 中等 | 极高（百万~十亿参数） |
| 数据需求 | 相对较少 | 需要大规模数据 |
| 硬件依赖 | 低 | 高（依赖 GPU/TPU） |
| 应用范围 | 结构化数据 | 图像、语音、NLP 等非结构化数据 |


# 从深度学习到大模型
## 深度学习瓶颈  
| 问题 | 描述 |
| --- | --- |
| 任务特定 | 模型只能解决一个任务，迁移性弱 |
| 监督学习依赖强 | 训练需要大量标注数据 |
| 推理能力差 | 缺乏常识和复杂推理 |
| 模型小、单一 | 模型参数百万级，能力受限 |


## 大模型时代的三大转变  
| 项目 | 深度学习时代 | 大模型时代 |
| --- | --- | --- |
| 模型规模 | 百万到千万参数 | 数十亿到数千亿（甚至万亿） |
| 训练方式 | 监督学习 | 自监督 + 大数据预训练 |
| 模型能力 | 专用 | 通用（多任务、多模态） |


##  大模型的核心特点  
| 特点 | 描述 |
| --- | --- |
| 通用性强 | 一个模型可以应对 NLP 多个任务，甚至图像、语音等模态 |
| Few-shot / Zero-shot 能力 | 无需训练或仅需少量样本就能解决新任务 |
| 可拓展性 | 模型越大越强，性能近似线性增长（Scaling Laws） |
| 多模态能力 | 支持文本、图像、音频、视频等输入输出（GPT-4o、Gemini） |
| 工具化能力 | 能调用外部工具（如搜索、计算器、API） |


##  大模型引发的变革  
| AI 2.0（深度学习） | AI 3.0（大模型） |
| --- | --- |
| 训练任务特定模型 | 训练通用基础模型 |
| 依赖标签 | 使用自监督数据 |
| 小模型拼接多系统 | 单一大模型解决多任务 |
| 专家调参 | 自动对齐、人类反馈训练 |


# AGI
## 什么是 AGI  
**AGI（Artificial General Intelligence，人工通用智能）** 指的是一种：

+ 能像人类一样完成**任意智能任务**；
+ 能进行**跨任务迁移、推理与学习**；
+ 具有**持续学习、自我反思、动机与规划能力** 的智能系统。

简单说：AGI ≠ 只能对话/写代码/生成图像，而是能像人一样**通用地理解世界和解决问题**。

## 大模型与 AGI 的关系图谱  
| 方面 | 大模型（LLMs） | AGI |
| --- | --- | --- |
| 通用性 | 高，跨任务能力强 | 极高，任意任务都能适应 |
| 推理能力 | 有限（依赖上下文） | 强，能自主构建知识链 |
| 学习能力 | 静态模型，需微调 | 持续学习，自适应变化 |
| 记忆能力 | 上下文窗口临时记忆 | 长期记忆 + 知识持久化 |
| 意图/动机 | 无真正意图 | 有目标、有自我决策能力 |
| 工具能力 | 通过函数调用拓展 | 工具内化、灵活使用 |
| 自我反思 | 无 | 有元认知（知道自己知道什么） |


##  大模型是AGI的阶段  
我们可以用一个“进化图”来表示：

```plain
人工智能 → 机器学习 → 深度学习 → 大模型 → 智能体（Agent）→ AGI
```

+ 大模型是“逼近 AGI”过程中的基础能力载体
+ 如果说 **AGI 是目标**，那么 **大模型 + Agent 架构 + 工具能力 + 记忆系统** 是通往它的路径

#  AIGC  
## AIGC 是什么
**AIGC（AI-Generated Content）**，即 **“人工智能生成内容”**，指的是通过 AI（尤其是生成式模型）**自动生产文本、图像、音频、视频、代码等数字内容** 的过程。  

+ **AIGC** = **AI Generated Content**
+ 属于 **内容创作方式的一种范式变革**
+ 相对传统内容（人创作）与 PGC（专业内容）/UGC（用户内容）

## AIGC 的典型内容类型  
| 类型 | 示例 | 常用模型 |
| --- | --- | --- |
| 文本生成 | 写文章、写诗、摘要、对话 | GPT-4, Claude, GLM |
| 图像生成 | 插画、头像、壁纸、设计图 | DALL·E, Midjourney, SD |
| 音频生成 | 背景音乐、配音、拟人声音 | MusicLM, TTS 模型 |
| 视频生成 | 动态广告、数字人、短片 | Sora (OpenAI), Runway |
| 代码生成 | 自动补全、脚本生成 | Copilot, CodeWhisperer |
| 3D生成 | 模型、数字资产 | DreamFusion, GET3D |


##  AIGC 背后的技术基础  
| 技术层 | 代表 |
| --- | --- |
| 模型架构 | Transformer, Diffusion Model |
| 训练范式 | 自监督预训练、RLHF、人类对齐 |
| 多模态融合 | 文本 + 图像、语音 + 视频 |
| 工具链 | Prompt 编写、API调用、模型微调 |
| 基础设施 | GPU、TPU、vLLM、LoRA、推理加速器 |


## AIGC 与大模型、AGI 的区别和联系  
| 概念 | 定义 | 关系 |
| --- | --- | --- |
| AIGC | AI 生成的内容 | 是大模型的 **直接应用产物** |
| 大模型 | 基础语言/图像模型 | 为 AIGC 提供核心能力（如 GPT） |
| AGI | 通用人工智能 | AIGC 是它可掌握的“技能”之一，但远非全部 |


比喻理解：

+ **大模型**是“发动机”
+ **AIGC**是“发动机驱动下的应用（车）”
+ **AGI**是“驾驶员”——能开车、会换挡、能理解上下文目的地


