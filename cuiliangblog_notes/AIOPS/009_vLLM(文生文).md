# vLLM(æ–‡ç”Ÿæ–‡)

> æ¥æº: AIOPS
> åˆ›å»ºæ—¶é—´: 2025-07-13T08:03:07+08:00
> æ›´æ–°æ—¶é—´: 2026-01-11T09:44:00.643635+08:00
> é˜…è¯»é‡: 1396 | ç‚¹èµ: 0

---

# ä»‹ç»
## ä»€ä¹ˆæ˜¯ vLLM
vLLMï¼ˆVirtual Large Language Modelï¼‰æ˜¯ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å›¢é˜Ÿå¼€å‘çš„é«˜æ€§èƒ½å¤§æ¨¡å‹æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒç‰¹ç‚¹å›´ç»•æ˜¾å­˜ä¼˜åŒ–ã€é«˜ååé‡ã€çµæ´»æ€§å’Œæ˜“ç”¨æ€§å±•å¼€ã€‚

å¯¹æ¯” ollama ä½œä¸ºä¸ªäººå¼€å‘è€…éƒ¨ç½²æ¨¡å‹å·¥å…·è€Œè¨€ï¼ŒvLLM ä¸“æ³¨äºé«˜å¹¶å‘è¯·æ±‚å’Œå¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒï¼Œé€‚ç”¨äºä¼ä¸šçº§åº”ç”¨å’Œéœ€è¦é«˜æ•ˆæ¨ç†çš„åœºæ™¯ã€‚vLLM é€šè¿‡ä¼˜åŒ–å†…å­˜ç®¡ç†å’Œå¹¶å‘å¤„ç†ï¼Œé€‚åˆå¤„ç†é«˜è´Ÿè½½çš„ç”Ÿäº§ç¯å¢ƒ â€Œã€‚

## å¯¹æ¯” Ollama
| é¡¹ç›® | **vLLM** | **Ollama** |
| --- | --- | --- |
| ç›®æ ‡ç”¨æˆ· | ä¼ä¸šã€å¹³å°çº§æœåŠ¡ã€ç ”ç©¶äººå‘˜ | å¼€å‘è€…ã€æœ¬åœ°ç”¨æˆ·ã€è½»é‡éƒ¨ç½² |
| å®‰è£…æ–¹å¼ | PythonåŒ… + æ‰‹åŠ¨æ¨¡å‹é…ç½® | ä¸€é”®å®‰è£…ï¼Œè‡ªåŠ¨æ‹‰å–æ¨¡å‹ |
| ä½¿ç”¨æ–¹å¼ | ç¼–å†™ä»£ç /APIé›†æˆï¼Œéœ€è‡ªå·±å¤„ç†æ¨¡å‹ä¸‹è½½ | CLI æˆ– REST APIï¼Œä¸€å¥å‘½ä»¤å³å¯è¿è¡Œæ¨¡å‹ |
| æ”¯æŒæ¨¡å‹æ ¼å¼ | HuggingFace Transformersï¼ˆåŸç”Ÿæ¨¡å‹ï¼‰ | GGUF / ggmlï¼ˆé‡åŒ–æ¨¡å‹ï¼‰ |
| æ”¯æŒæ¨¡å‹ç±»å‹ | ChatGPTç±» LLMï¼Œå¦‚ LLaMAã€Mistralã€GPT ç­‰ | åŒä¸Šï¼Œä½†é€šå¸¸åªæ”¯æŒ Ollama æ ¼å¼æ¨¡å‹ |
| æ˜¯å¦æ”¯æŒæ‰¹é‡æ¨ç† | âœ…ï¼ˆæ”¯æŒè¿ç»­ batchingï¼Œé€‚åˆé«˜å¹¶å‘ï¼‰ | âŒï¼ˆä¸»è¦æ˜¯å•ä¸ªç”¨æˆ·è¯·æ±‚åœºæ™¯ï¼‰ |
| KV Cache ç®¡ç† | âœ… é«˜æ€§èƒ½åŠ¨æ€ KV Cache | âœ… æœ‰ç¼“å­˜ï¼Œä½†ä¸å¦‚ vLLM ç²¾ç»† |
| æ¨ç†æ€§èƒ½ | ğŸš€ é€‚åˆé«˜ååé‡/é«˜å¹¶å‘ç”Ÿäº§ç¯å¢ƒ | ğŸ¢ é€šå¸¸åªé€‚åˆæœ¬åœ°æ¡Œé¢äº¤äº’ä½¿ç”¨ |
| æ¨¡å‹åˆ‡æ¢/ç®¡ç† | éœ€è‡ªå·±é…ç½®è·¯å¾„/æƒé‡/Tokenizer ç­‰ | ç®€å• `ollama run llama2` |
| é‡åŒ–æ¨¡å‹æ”¯æŒ | ä¸»è¦æ”¯æŒ FP16/BF16ï¼ˆå¯é€‰ INT4/8ï¼‰ | ä¸»è¦ä½¿ç”¨ GGUFï¼ˆQ4_K_Mã€Q8_0 ç­‰é‡åŒ–æ ¼å¼ï¼‰ |
| GPU æ”¯æŒ | âœ… å¤š GPU æ”¯æŒè‰¯å¥½ | âœ… æ”¯æŒ GPU |
| å¤šè¯­è¨€/å¤šæ¨¡å‹æ”¯æŒ | âœ… å¯è·‘å¤šä¸ªæ¨¡å‹å®ä¾‹ï¼Œçµæ´»é…ç½® | âŒ é€šå¸¸åªèƒ½è·‘ä¸€ä¸ªæ¨¡å‹ |
| æ”¯æŒæµå¼è¾“å‡º | âœ… æ˜¯è®¾è®¡ç›®æ ‡ä¹‹ä¸€ | âœ… æ”¯æŒ |
| Web UI | âŒï¼ˆéœ€è‡ªå·±æ­å»ºï¼‰ | âœ… å®˜æ–¹å¸¦ Web UI |


## é«˜æ€§èƒ½ä¼˜åŠ¿
### **åˆ†é¡µæ³¨æ„åŠ›æœºåˆ¶**
æ ¸å¿ƒåˆ›æ–°ï¼šå€Ÿé‰´æ“ä½œç³»ç»Ÿè™šæ‹Ÿå†…å­˜åˆ†é¡µæœºåˆ¶ï¼Œå°†æ³¨æ„åŠ›è®¡ç®—ä¸­çš„**Key/Value ç¼“å­˜ï¼ˆKV Cacheï¼‰**åˆ’åˆ†ä¸ºå›ºå®šå¤§å°çš„â€œé¡µâ€ï¼ŒåŠ¨æ€åˆ†é…æ˜¾å­˜ï¼Œæ˜¾è‘—å‡å°‘å†…å­˜ç¢ç‰‡åŒ–ã€‚

+ ä¼ ç»Ÿé—®é¢˜ï¼šä¼ ç»Ÿæ¡†æ¶éœ€ä¸ºæ¯ä¸ªè¯·æ±‚é¢„åˆ†é…è¿ç»­æ˜¾å­˜ç©ºé—´ï¼Œå¯¼è‡´åˆ©ç”¨ç‡ä½ï¼ˆä»… 20%-40%ï¼‰ã€‚
+ vLLM è§£å†³æ–¹æ¡ˆï¼šæŒ‰éœ€åˆ†é…æ˜¾å­˜é¡µï¼Œæ”¯æŒåŠ¨æ€æ‰©å±•ï¼Œæ˜¾å­˜åˆ©ç”¨ç‡æå‡è‡³æ¥è¿‘ 100%ã€‚

ä¾‹å¦‚ï¼ŒLLaMA-7B æ¨¡å‹æ˜¾å­˜å ç”¨å¯ä» 14GB å‹ç¼©è‡³ 4GBï¼ˆä½¿ç”¨ [INT4 é‡åŒ–](https://zhida.zhihu.com/search?content_id=258701331&content_type=Article&match_order=1&q=INT4+%E9%87%8F%E5%8C%96&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NTI2Mzg1MDYsInEiOiJJTlQ0IOmHj-WMliIsInpoaWRhX3NvdXJjZSI6ImVudGl0eSIsImNvbnRlbnRfaWQiOjI1ODcwMTMzMSwiY29udGVudF90eXBlIjoiQXJ0aWNsZSIsIm1hdGNoX29yZGVyIjoxLCJ6ZF90b2tlbiI6bnVsbH0.gztzw_p6ogwp2RM7JPHtE3nHaoH5XEcVWyfd9KExTjI&zhida_source=entity)ï¼‰ã€‚ æ”¯æŒé•¿ä¸Šä¸‹æ–‡ï¼ˆå¦‚ 128K æˆ– 10M tokenï¼‰çš„é«˜æ•ˆå¤„ç†ï¼Œå‡å°‘æ˜¾å­˜æµªè´¹ã€‚

### **è¿ç»­æ‰¹å¤„ç†**
åŠ¨æ€åˆå¹¶è¯·æ±‚ï¼šå®æ—¶åˆå¹¶å¤šä¸ªæ¨ç†è¯·æ±‚ï¼Œé¿å…é™æ€æ‰¹å¤„ç†çš„ç­‰å¾…å»¶è¿Ÿï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ã€‚

ååé‡æå‡ï¼š

+ ç›¸æ¯” Hugging Face Transformersï¼Œååé‡æå‡ 24 å€ï¼ˆå¦‚ LLaMA-7B æ¨¡å‹ï¼‰ã€‚
+ åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹ï¼Œååé‡å¯è¾¾ä¼ ç»Ÿæ¡†æ¶çš„ 5-10 å€ã€‚

### **é‡åŒ–æ”¯æŒ**
å…¼å®¹ä¸»æµé‡åŒ–æ–¹æ³•ï¼šæ”¯æŒ GPTQã€AWQã€SqueezeLLMã€FP8 KV Cache ç­‰ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨å’Œè®¡ç®—å¼€é”€ã€‚

é‡åŒ–æ•ˆæœï¼š

+ INT4 é‡åŒ–ï¼šå°† 7B æ¨¡å‹æ˜¾å­˜éœ€æ±‚ä» 14GB å‹ç¼©è‡³ 4GBï¼ŒåŒæ—¶ä¿æŒç²¾åº¦æŸå¤±<1%ã€‚
+ é€‚ç”¨äºæ¶ˆè´¹çº§æ˜¾å¡ï¼ˆå¦‚ RTX 4090ï¼‰éƒ¨ç½² 7B-13B æ¨¡å‹ã€‚

### **é«˜æ€§èƒ½ä¸åˆ†å¸ƒå¼æ¨ç†**
å¤š GPU å¼ é‡å¹¶è¡Œï¼šæ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²ï¼Œä¾‹å¦‚åœ¨ 4 å— A100 GPU ä¸Šè¿è¡Œ 70B å‚æ•°æ¨¡å‹ã€‚

CUDA ä¼˜åŒ–ï¼šä½¿ç”¨ CUDA/HIP å›¾ï¼ˆCUDA Graphsï¼‰åŠ é€Ÿæ¨¡å‹æ‰§è¡Œã€‚ é«˜æ€§èƒ½ CUDA å†…æ ¸ä¼˜åŒ–ï¼Œå‡å°‘è®¡ç®—å»¶è¿Ÿã€‚

## æ˜“ç”¨æ€§ä¼˜åŠ¿
### æ˜“ç”¨æ€§ä¸å…¼å®¹æ€§
ä¸ Hugging Face æ— ç¼é›†æˆï¼šæ”¯æŒ 50+ä¸»æµæ¨¡å‹ï¼ˆå¦‚ LLaMAã€Qwenã€Mistralã€XVERSE ç­‰ï¼‰ã€‚

OpenAI API å…¼å®¹ï¼šå¯ç›´æ¥æ›¿æ¢ OpenAI æ¥å£ï¼Œæä¾›æ ‡å‡† API æœåŠ¡ï¼ˆå¦‚/v1/completionsï¼‰ã€‚

çµæ´»çš„éƒ¨ç½²é€‰é¡¹ï¼šæ”¯æŒæµå¼è¾“å‡ºã€å‰ç¼€ç¼“å­˜ã€å¤š LoRA é€‚é…åŠç¦»çº¿æ‰¹é‡æ¨ç†ã€‚

### **è§£ç ç®—æ³•å¤šæ ·æ€§**
å¹¶è¡Œé‡‡æ ·ï¼ˆParallel Samplingï¼‰ï¼šå•æ¬¡å‰å‘ä¼ æ’­ç”Ÿæˆå¤šä¸ªè¾“å‡ºï¼ˆå¦‚å¤šç§å›ç­”ï¼‰ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚

æ³¢æŸæœç´¢ï¼ˆBeam Searchï¼‰ï¼šæå‡ç”Ÿæˆæ–‡æœ¬çš„å‡†ç¡®æ€§å’Œå¤šæ ·æ€§ã€‚

è‡ªå®šä¹‰è§£ç ç­–ç•¥ï¼šæ”¯æŒæ ¹æ®åœºæ™¯é€‰æ‹©æœ€ä¼˜è§£ç ç®—æ³•ã€‚

# æ¨¡å‹éƒ¨ç½²
## éƒ¨ç½²ç¯å¢ƒå‡†å¤‡
vLLM æ˜¯ä¸€ä¸ª Python åº“ï¼ŒåŒ…å«é¢„ç¼–è¯‘çš„ C++ å’Œ CUDAäºŒè¿›åˆ¶æ–‡ä»¶ã€‚

æ¥ä¸‹æ¥ä½¿ç”¨ 4 å¼  H100 80G æ˜¾å¡å¹¶è¡Œè·‘ DeepSeek-R1 32Bæ¨¡å‹  

ä¸ºæ–¹ä¾¿éƒ¨ç½²ä½¿ç”¨ï¼Œé€šè¿‡ docker æ–¹æ¡ˆéƒ¨ç½²ï¼Œéœ€è¦å¯¹ç³»ç»Ÿç¯å¢ƒè¿›è¡Œåˆå§‹åŒ–é…ç½®ï¼Œå…·ä½“å¯å‚è€ƒæ–‡æ¡£ï¼š[https://www.cuiliangblog.cn/detail/section/189768582](https://www.cuiliangblog.cn/detail/section/189768582)

## ä¸‹è½½æ¨¡å‹æƒé‡
æˆ‘ä»¬å¯ä»¥æå‰ä¸‹è½½æ¨¡å‹æƒé‡åˆ°æœ¬åœ°ç›®å½•ï¼Œå¯åŠ¨æ—¶æŒ‡å®šæ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„æ—¢å¯ï¼Œé¿å…å¯åŠ¨è¿‡ç¨‹ä¸­ä¸‹è½½è¶…æ—¶ã€‚

ç”±äºç›´æ¥ä»huggingface ä¸‹è½½æ•°æ®å¯èƒ½ä¼šå‡ºç°è¶…æ—¶æƒ…å†µï¼Œå› æ­¤å»ºè®®ç™»å½•[https://modelscope.cn/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B](https://modelscope.cn/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B)å›½å†…ç«™ç‚¹ï¼Œè·å–ä¸‹è½½å‘½ä»¤

```bash
# å®‰è£…modelscopeä¸‹è½½å·¥å…·
pipx install modelscope
# ä¸‹è½½deepseekæ¨¡å‹æƒé‡åˆ°æŒ‡å®šç›®å½•
modelscope download --model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B --local_dir /mnt/afs/hf_models --max-workers=10

 _   .-')                _ .-') _     ('-.             .-')                              _ (`-.    ('-.
( '.( OO )_             ( (  OO) )  _(  OO)           ( OO ).                           ( (OO  ) _(  OO)
 ,--.   ,--.).-'),-----. \     .'_ (,------.,--.     (_)---\_)   .-----.  .-'),-----.  _.`     \(,------.
 |   `.'   |( OO'  .-.  ',`'--..._) |  .---'|  |.-') /    _ |   '  .--./ ( OO'  .-.  '(__...--'' |  .---'
 |         |/   |  | |  ||  |  \  ' |  |    |  | OO )\  :` `.   |  |('-. /   |  | |  | |  /  | | |  |
 |  |'.'|  |\_) |  |\|  ||  |   ' |(|  '--. |  |`-' | '..`''.) /_) |OO  )\_) |  |\|  | |  |_.' |(|  '--.
 |  |   |  |  \ |  | |  ||  |   / : |  .--'(|  '---.'.-._)   \ ||  |`-'|   \ |  | |  | |  .___.' |  .--'
 |  |   |  |   `'  '-'  '|  '--'  / |  `---.|      | \       /(_'  '--'\    `'  '-'  ' |  |      |  `---.
 `--'   `--'     `-----' `-------'  `------'`------'  `-----'    `-----'      `-----'  `--'      `------'

Downloading Model from https://www.modelscope.cn to directory: /mnt/afs/hf_models

Successfully Downloaded from model deepseek-ai/DeepSeek-R1-Distill-Qwen-32B.
```

é™¤äº†ä½¿ç”¨é­”å¡”å¤–ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨[https://hf-mirror.com/](https://hf-mirror.com/)é•œåƒç«™ä¸‹è½½æ¨¡å‹æƒé‡ã€‚

```yaml
# è®¾ç½®ä¸‹è½½åœ°å€
export HF_ENDPOINT="https://hf-mirror.com"
# å®‰è£…huggingface-cliä¸‹è½½å·¥å…·
pip3 install -U huggingface_hub
# ä¸‹è½½æ¨¡å‹æƒé‡
# hf download \
  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \
  --local-dir /mnt/afs/hf_models/DeepSeek-R1-Distill-Qwen-32B 
```

## k8s<font style="color:rgb(41, 49, 61);">å•æœº TP æ¨¡å¼</font>éƒ¨ç½²
ç™»å½•huggingface[https://huggingface.co/deepseek-ai/DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1) è·å–å¯åŠ¨å‘½ä»¤

![](https://via.placeholder.com/800x600?text=Image+91c1c46757acdc33)

æŒ‰ç…§æç¤ºå‚æ•°ï¼Œæˆ‘ä»¬è¿›è¡Œä¸€äº›è°ƒæ•´

```bash
docker run -d \
  -e CUDA_VISIBLE_DEVICES=0,1,2,3 \
  -e TORCH_CUDA_ARCH_LIST="8.0" \
  --gpus all \
  --name vllm-deepseek-r1 \
  -v /mnt/afs/hf_models:/models \
  -p 8000:8000 \
  --ipc=host \
  --shm-size=64g \
  swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/vllm/vllm-openai:v0.9.2 \
  --model /models \
  --tensor-parallel-size 4 \
  --dtype float16 \
  --max-model-len 128000 \
  --api-key my-secret-key
```

docker å‚æ•°é¡¹è¯´æ˜ï¼š

| å‚æ•° | è¯´æ˜ |
| --- | --- |
| `CUDA_VISIBLE_DEVICES=0,1,2,3` | æŒ‡å®šä½¿ç”¨å‰ 4 å¼ æ˜¾å¡è¿è¡Œ |
| ` TORCH_CUDA_ARCH_LIST="8.0"` | æŒ‡å®š A100 GPU æ¶æ„ï¼Œé¿å…é»˜è®¤ç¼–è¯‘æ‰€æœ‰æ¶æ„   |
| `--gpus all` |  ä¸Šè¿° 4 å¼ æ˜¾å¡å…¨éƒ¨åˆ†é…è¿›å®¹å™¨  |
| `-v /mnt/local-nvme/hf_models:/root/.cache/huggingface` | å°†å®¿ä¸»æœºçš„ `/data/hf_models`<br/> æ˜ å°„ä¸ºå®¹å™¨å†… HuggingFace ç¼“å­˜ç›®å½•ï¼Œé¿å…æ¯æ¬¡é‡æ–°ä¸‹è½½æ¨¡å‹ |
| `-p 8000:8000` | å°†å®¹å™¨å†… API ç«¯å£ 8000 æ˜ å°„åˆ°ä¸»æœºç«¯å£ 8000 |
| `--ipc=host` | ä½¿ç”¨ä¸»æœºçš„è¿›ç¨‹é—´é€šä¿¡æœºåˆ¶ï¼ˆé¿å…å¤šè¿›ç¨‹æ¨¡å‹æ­»é”ï¼‰ |
| `--shm-size 64g` | è®¾ç½®å…±äº«å†…å­˜ï¼ˆshared memoryï¼‰å¤§å°ä¸º 64GBï¼Œé˜²æ­¢è¿è¡Œä¸­å‡ºç° OOM é”™è¯¯ |
| `vllm/vllm:latest` | ä½¿ç”¨ vLLM å®˜æ–¹å‘å¸ƒçš„æœ€æ–°é•œåƒï¼ˆå« Triton æ¨ç†ä¼˜åŒ–ï¼‰ |


vllm å¯åŠ¨å‚æ•°è¯´æ˜ï¼š

| å‚æ•° | è¯´æ˜ |
| --- | --- |
| `--model /models` | æŒ‡å®šæ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ |
| `--tensor-parallel-size 4` | å¯åŠ¨ **4 å¼  GPU çš„å¼ é‡å¹¶è¡Œ**ï¼Œæ¯å¼ å¡åˆ†æ‹… 1/4 çš„æ¨¡å‹æƒé‡å’Œè®¡ç®— |
| `--dtype float16` | ä½¿ç”¨åŠç²¾åº¦æ¨ç†ï¼ˆFP16ï¼‰ï¼Œæ˜¾è‘—å‡å°‘æ˜¾å­˜å ç”¨ï¼Œæé«˜æ¨ç†é€Ÿåº¦ |
| `--max-model-len 128000` | è®¾ç½®ä¸Šä¸‹æ–‡çª—å£ä¸º 128K tokensï¼ˆDeepSeek-R1 æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡ï¼‰ |
| `--api-key my-secret-key` |  å¯ç”¨ API å¯†é’¥éªŒè¯   |


æŸ¥çœ‹ å®¹å™¨è¿è¡ŒçŠ¶æ€

```bash
docker ps                                                                                                                                                              
CONTAINER ID   IMAGE                                                                        COMMAND                  CREATED          STATUS          PORTS                    NAMES                            
63f381ea7223   swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/vllm/vllm-openai:v0.9.2   "python3 -m vllm.entâ€¦"   20 seconds ago   Up 12 seconds   0.0.0.0:8000->8000/tcp   vllm-deepseek-r1
```

è®¿é—® 8000 æ¥å£ï¼ŒæŸ¥çœ‹æ¨¡å‹ä¿¡æ¯

```bash
# curl http://localhost:8000/v1/models -H "Authorization: Bearer my-secret-key"
{"object":"list","data":[{"id":"/models","object":"model","created":1752587580,"owned_by":"vllm","root":"/models","parent":null,"max_model_len":128000,"permission":[{"id":"modelperm-e49e7eec185d4af0812fb3710beee4c4","object":"model_permission","created":1752587580,"allow_create_engine":false,"allow_sampling":true,"allow_logprobs":true,"allow_search_indices":false,"allow_view":true,"allow_fine_tuning":false,"organization":"*","group":null,"is_blocking":false}]}]}#  
```

## k8s <font style="color:rgb(41, 49, 61);">å¤šæœº TP æ¨¡å¼</font>éƒ¨ç½²
é™¤äº†å•æœºå¤šå¡å¤–ï¼ŒvLLM æ”¯æŒ**å¤šèŠ‚ç‚¹ï¼ˆmulti-nodeï¼‰åˆ†å¸ƒå¼éƒ¨ç½²**ï¼Œå°¤å…¶é€‚åˆåƒä½ è¿™ç§è¦éƒ¨ç½² **DeepSeek-R1 è¿™ç±»å¤§æ¨¡å‹**ï¼Œå•æœºæ˜¾å­˜ä¸å¤Ÿæ—¶éå¸¸æœ‰ç”¨ï¼Œéœ€è¦ä½¿ç”¨ ray+vllm å®ç°ã€‚æ¥ä¸‹æ¥ä½¿ç”¨ k8s æ¼”ç¤ºä½¿ç”¨ 2 ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹ 2 å¼ æ˜¾å¡éƒ¨ç½² deepseek-r1ã€‚

èµ„æºæ¸…å•å†…å®¹å¦‚ä¸‹ï¼š

```yaml
apiVersion: v1
kind: Service
metadata:
  name: vllm-headless
  labels:
    app: vllm
spec:
  clusterIP: None
  selector:
    app: vllm
  ports:
    - name: http
      port: 8000
      targetPort: 8000
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: vllm
spec:
  serviceName: vllm-headless
  replicas: 2  # 2 èŠ‚ç‚¹
  selector:
    matchLabels:
      app: vllm
  template:
    metadata:
      labels:
        app: vllm
    spec:
      restartPolicy: Always
      containers:
        - name: vllm
          image: swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/vllm/vllm-openai:v0.9.2
          ports:
            - containerPort: 8000
          env:
            - name: TORCH_CUDA_ARCH_LIST
              value: "8.0"
          command: ["python3"]
          args:
            - -m
            - vllm.entrypoints.openai.api_server
            - --model
            - /models
            - --tensor-parallel-size # å¼ é‡å¹¶è¡Œå¤§å°
            - "2"
            - --pipeline-parallel-size # ç®¡é“å¹¶è¡Œå¤§å°
            - "2"
            - --dtype
            - float16
            - --max-model-len
            - "128000"
            - --api-key
            - my-secret-key
          volumeMounts:
            - mountPath: /models
              name: model-volume
          resources:
            limits:
              nvidia.com/gpu: '2'  # æ¯èŠ‚ç‚¹ 2 å¼  GPU
              cpu: '2'
              memory: 10Gi
      volumes:
        - name: model-volume
          hostPath:
            path: /mnt/afs/hf_models
            type: Directory

```

æŸ¥çœ‹èµ„æºçŠ¶æ€

```yaml
# kubectl get pod -o wide
NAME        READY   STATUS    RESTARTS   AGE     IP             NODE       NOMINATED NODE   READINESS GATES
vllm-0      1/1     Running   0          2m19s   10.240.0.40    real-334   <none>           <none>
vllm-1      1/1     Running   0          2m19s   10.240.0.41    real-335   <none>           <none>
# kubectl get svc              
NAME             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
vllm-headless    ClusterIP   None             <none>        8000/TCP   2m19s
```

# è·Ÿ vLLM æ¨ç†æœåŠ¡äº¤äº’
## é€šè¿‡ python ä»£ç äº¤äº’
æœåŠ¡å™¨è¿è¡Œåï¼Œå¯ä»¥é€šè¿‡ python ä»£ç è°ƒç”¨å…¶ APIï¼š

```plain
from openai import OpenAI

client = OpenAI(base_url='http://localhost:3000/v1', api_key='na')

# Use the following func to get the available models
# model_list = client.models.list()
# print(model_list)

chat_completion = client.chat.completions.create(
   model="deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
   messages=[
      {
            "role": "user",
            "content": "Tell me something about large language models."
      }
   ],
   stream=True,
)
for chunk in chat_completion:
   print(chunk.choices[0].delta.content or"", end="")
```

## é€šè¿‡ cli äº¤äº’
```plain
curl -X POST "http://localhost:8000/v1/chat/completions" \
 -H "Content-Type: application/json" \
 --data '{
  "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
  "messages": [
   {
    "role": "user",
    "content": "What is the capital of France?"
   }
  ]
 }
```




