# 大模型架构

> 来源: AIOPS
> 创建时间: 2025-07-17T15:06:15+08:00
> 更新时间: 2026-01-11T09:43:56.021192+08:00
> 阅读量: 2159 | 点赞: 0

---

# Transformer 架构
参考文档：[https://www.runoob.com/nlp/transformer-architecture.html](https://www.runoob.com/nlp/transformer-architecture.html)

公众号文章：[https://mp.weixin.qq.com/s/bQE58LII4nXvO2hkjlYvsw](https://mp.weixin.qq.com/s/bQE58LII4nXvO2hkjlYvsw)

# <font style="color:rgb(0, 0, 0);background-color:rgb(250, 252, 253);">BERT</font> 模型
参考文档：[https://www.runoob.com/nlp/bert-encoder.html](https://www.runoob.com/nlp/bert-encoder.html)

公众号文章：[https://mp.weixin.qq.com/s/0wA8BMGrJxWYDu0HAl7Bhg](https://mp.weixin.qq.com/s/0wA8BMGrJxWYDu0HAl7Bhg)

# GPT 架构
参考文档：[https://www.runoob.com/nlp/generative-pre-trained-transformer.html](https://www.runoob.com/nlp/generative-pre-trained-transformer.html)

公众号文章：[https://mp.weixin.qq.com/s/S-gdaAn3izW2NC70-MZjuw](https://mp.weixin.qq.com/s/S-gdaAn3izW2NC70-MZjuw)

# MoE 模型
公众号文章：[https://mp.weixin.qq.com/s/I9L3Ldw6s5Ui3vbPX5g8mw](https://mp.weixin.qq.com/s/I9L3Ldw6s5Ui3vbPX5g8mw)


