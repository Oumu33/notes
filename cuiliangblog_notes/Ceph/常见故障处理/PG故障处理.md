# PG故障处理

> 分类: Ceph > 常见故障处理
> 更新时间: 2026-01-10T23:35:18.348014+08:00

---

# PG 状态查询
## 查看集群健康状态
```plain
ceph health detail
```

输出的 `HEALTH_WARN` 或 `HEALTH_ERR` 通常会提示与 PG 相关的问题，例如 PG 不活动、未清理或丢失。

## 查询 PG 详细状态
```plain
ceph pg dump
```

显示所有 PG 的完整信息，包括状态、数据分布等。

## 按状态过滤 PG
```plain
ceph pg ls-by-state <pg_state>
```

常见 PG 状态包括：

+ `active+clean`: 正常状态，数据完全健康。
+ `stale`: PG 未更新状态，可能网络问题或 OSD 离线。
+ `inactive`: PG 未被激活，无法提供服务。
+ `degraded`: 数据分布不完整，但可用。
+ `undersized`: 副本数少于期望值。
+ `peering`: PG 正在进行副本协调。
+ `backfilling/recovering`: 数据恢复中。
+ `down`: PG 处于不可用状态。

## 查看特定 PG 状态
```plain
ceph pg 1.2 query
```

可查看 PG 的状态详情、包含的 OSD 等。

# PG常见状态总结
## peering
正在同步状态，同一个PG中的OSD需要将准备数据同步一致，而peering（对等）就是OSD同步过程中的状态。

## activating
Peering 已经完成，PG正在等待所有PG实例同步Peering的结果(Info、Log等)

## clean
干净态，PG当前不存在待修复的对象，并且大小等于存储池的副本数，即PG的活动集(Acting Set)和上行集(Up Set)为同一组OSD且内容一致。  
活动集(Acting Set)：由PG当前主的OSD和其余处于活动状态的备用OSD组成，当前PG内的OSD负责处理用户的读写请求。  
上行集(Up Set)：在某一个OSD故障时，需要将故障的OSD更换为可用的OSD，并主PG内部的主OSD同步数据到新的OSD上，例如PG内有OSD1、OSD2、OSD3，当OSD3故障后需要用OSD4替换OSD3，那么OSD1、OSD2、OSD3就是上行集，替换后OSD1,OSD2、OSD4就是活动集，OSD替换完成后活动集最终要替换上行集。

## active
就绪状态或活跃状态，Active表示主OSD和备OSD处于正常工作状态，此时的PG可以正常处理来自客户端的读写请求，正常的PG默认就是Active+Clean状态。

```bash
cephadmin@ceph-deploy:~$ ceph pg stat
97 pgs: 97 active+clean; 43 MiB data, 5.9 GiB used, 20 TiB / 20 TiB avail
```

## degraded
降级状态，该状态出现于OSD被标记为down以后，那么其他映射到此OSD的PG都会转换到降级状态。  
如果此OSD还能重新启动完成并完成Peering操作后,那么使用此OSD的PG将重新恢复为clean状态。  
如果此OSD被标记为down的时间超过5分钟还没有修复，那么此OSD将会被ceph踢出集群，然后ceph会对被降级的PG启动恢复操作，直到所有由于此OSD而被降级的PG重新恢复为clean状态。  
恢复数据会从PG内的主OSD恢复，如果是主OSD故障，那么会在剩下的两个备用OSD重新选择一个作为主OSD。

## stale
过期状态，正常情况下每个主OSD都要周期性的向RADOS集群中的监视器(Mon)报告其作为主OSD所持有的所有PG的最新统计数据，因任何原因导致某个OSD无法正常向监视器发送汇报信息的、或者由其他OSD报告某个OSD已经down 的时候，则所有以此OSD为主PG则会立即被标记为stale状态，即他们的主OSD已经不是最新的数据了，如果是备份的OSD发送down的时候，则ceph会执行修复而不会触发PG状态转换为stale状态。

## undersized
小于正常状态，PG当前副本数小于其存储池定义的值的时候，PG会转换为undersized状态，比如两个备份OSD都down了，那么此时PG中就只有一个主OSD了，不符合ceph最少要求一个主OSD加一个备OSD的要求，那么就会导致使用此OSD的PG转换为undersized 状态，直到添加备份OSD添加完成，或者修复完成。

## scrubbing
scrub是ceph对数据的清洗状态，用来保证数据完整性的机制，Ceph 的OSD定期启动scrub线程来扫描部分对象，通过与其他副本比对来发现是否一致，如果存在不一致，抛出异常提示用户手动解决, scrub 以PG为单位，对于每一个pg， ceph分析该pg下所有的object，产生一个类似于元数据信息摘要的数据结构,如对象大小,属性等,叫scrubmap,比较主与副scrubmap，来保证是不是有object丢失或者不匹配，扫描分为轻量级扫描和深度扫描，轻量级扫描也叫做light scrubs或者shallow scrubs或者simply scrubs即轻量级扫描.  
Light scrub(daily)比较object size 和属性, deep scrub (weekly)读取数据部分并通过checksum(CRC32算法)对比和数据的一致性,深度扫描过程中的PG会处于scrubbing+deep状态.

## recovering
正在恢复态，集群正在执行迁移或同步对象和他们的副本，这可能是由于添加了一个新的OSD到集群中或者某个OSD宕掉后，PG可能会被CRUSH算法重新分配不同的OSD，而由于OSD更换导致PG发生内部数据同步的过程中的PG会被标记为Recovering.

## backfilling
正在后台填充态, backfill是recovery 的一种特殊场景，指peering完成后，如果基于当前权威日志无法对Up Set(上行集)当中的某些PG实例实施增量同步(例如承载这些PG实例的OSD离线太久,或者是新的OSD加入集群导致的PG实例整体迁移)则通过完全拷贝当前Primary所有对象的方式进行全量同步，此过程中的PG会处于backfilling.

## backfill-toofull
某个需要被backfill的PG实例，其所在的OSD可用空间不足，Backfill流程当前被挂起时PG给的状态。

