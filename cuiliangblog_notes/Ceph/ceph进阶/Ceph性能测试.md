# Ceph性能测试

> 分类: Ceph > ceph进阶
> 更新时间: 2026-01-10T23:35:18.684527+08:00

---

# 测试工具
不同于fio、vdbench等上层应用接口测试工具，ceph提供了一些自带的基准性能测试工具，用于测试rados、rbd等底层存储基准性能，可以比对底层基准性能和上层应用基准性能，确定潜在可调优的空间

+ rados bench：为ceph自带的基准测试工具，rados bench用于测试rados存储池底层性能，该工具可以测试写、顺序读、随机读三种类型
+ rbd bench：ceph自带的基准性能测试工具，rbd bench用于测试块设备的吞吐量

# rados bench
## 测试参数
```bash
rados bench -p <pool_name> <seconds> <write|seq|rand> [-b block_size] [-t concurrent_operations] [-k /.../ceph.client.admin.keyring] [-c /.../ceph.conf] [--no-cleanup] [--run-name run_name]
```

+ -p <pool_name>：   
测试存储池名称
+ <seconds>：   
测试运行时长，单位为s
+ <write|seq|rand>：   
测试读写类型（write：写，seq：顺序读，rand：随机读）
+ -b <block_size>：   
测试读写块大小，默认为4MB，默认单位为字节   
当存储池为纠删存储类型时，则最小测试文件大小与EC Stripe Width（默认4K）值相等   
注：当文件大小不满足该值时，程序会自动调整为EC Stripe Width值
+ -t concurrent_operation   
测试读写并发线程数，默认为16
+ -k /.../ceph.client.admin.keyring   
指定测试`ceph.client.admin.keyring`配置文件路径
+ -c /.../ceph.conf   
指定测试`ceph.conf`配置文件路径
+ --no-cleanup   
表示测试完成后不删除测试数据，只对写有效   
通常在读测试之前，需要执行写测试生成测试数据之后，再执行读测试   
生成的测试文件可通过命令`rados -p {pool_name} cleanup`删除
+ **--run-name run_name**   
表示测试生成的对象名称

## 注意事项
测试前建议刷新所有文件系统缓存，以便于保证性能数据准确性

```bash
echo 3 | sudo tee /proc/sys/vm/drop_caches && sudo sync
```

清理存储池数据

```plain
rados cleanup -p mypool
```

## 写入性能测试
向 mypool 存储池测试 1分钟，顺序写入 1M 块的数据，并发 32 线程，测试完成后不删除测试数据。

```bash
root@ceph-1:~# rados bench -p mypool 60 write -b 1M -t 32 --run-name 1M-write --no-cleanup
hints = 1
Maintaining 32 concurrent writes of 1048576 bytes to objects of size 1048576 for up to 60 seconds or 0 objects
Object prefix: benchmark_data_ceph-1_11431 # 生成的对象名称的前缀为
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
……
   62      30       102        72   1.16082         0           -      14.977
Total time run:         62.366 # 实际运行的总时间
Total writes made:      102 # 总共执行了 102 次写操作
Write size:             1048576 # 单次写操作的大小为 1 MB
Object size:            1048576 # 对象的大小为 1 MB
Bandwidth (MB/sec):     1.63551 # 整个测试期间的平均写入带宽
Stddev Bandwidth:       2.55361 # 写入带宽的标准差，表明带宽波动情况
Max bandwidth (MB/sec): 20 # 写入带宽的最大值
Min bandwidth (MB/sec): 0 # 写入带宽的最小值
Average IOPS:           1 # 整个测试期间的平均 IOPS
Stddev IOPS:            2.56533 # IOPS 的标准差
Max IOPS:               20 # IOPS 的最大值
Min IOPS:               0 # IOPS 的最小值
Average Latency(s):     19.5217 # 平均写操作延迟
Stddev Latency(s):      13.0786 # 延迟的标准差
Max latency(s):         62.2725 # 写操作的最大延迟
Min latency(s):         0.0434128 # 写操作的最小延迟
```

## 读取性能测试
向 mypool 存储池测试 1分钟，写入顺序读 1M 块的数据，并发 32 线程。

```bash
rados bench -p mypool 60 seq -t 32 --run-name 1M-seq-read
```

# rbd bench
## 测试参数
```plain
rbd bench <rbd-name> --io-type  <io-type>  --io-size <io-size> --io-pattern <io-pattern>  --io-threads <io-threads> --io-total <total-size>
```

+ **rbd-name**：指定测试块设备名称，如rbd/rbd01
+ **--io-type**：指定测试IO类型，可选参数`write`、`read`
+ **--io-size**：指定测试IO块大小，单位为`byte`，默认参数为`4096`（4KB）
+ **--io-pattern**：指定测试IO模式，可选参数为`seq`（顺序）、`rand`（随机）
+ **--io-threads**：指定测试IO线程数，默认参数为`16`
+ **--io-total**：指定测试总写入数据量，单位为`byte`，默认参数为`1073741824`（1G）

## 注意事项
测试前先创建镜像

```bash
root@ceph-1:~# rbd create data-img --size 50G --pool mypool
root@ceph-1:~# rbd ls --pool mypool -l
NAME      SIZE    PARENT  FMT  PROT  LOCK
data-img  50 GiB            2            
```

测试完成后，生成的数据不会自动清理。如果不需要测试数据，可以手动删除：

```plain
rbd rm -p rbd mypool/data-img
```

或者使用 `--io-cleanup` 选项。

## 大文件带宽测试
+ 1M顺序写   
对 mypool 存储池下的 data-img 镜像进行测试，指定线程数为32， 每次 I/O 操作的数据块大小为 1 MB，写入数据量为 10G

```bash
root@ceph-1:~# rbd bench mypool/data-img --io-type write --io-size 1M --io-pattern seq  --io-threads 32 --io-total 10G
bench  type write io_size 1048576 io_threads 32 bytes 10737418240 pattern sequential
  SEC       OPS   OPS/SEC   BYTES/SEC
……
  588     10144   38.2937    38 MiB/s
elapsed: 590   ops: 10240   ops/sec: 17.3287   bytes/sec: 17 MiB/s
```

+ 1M顺序读   
指定线程数为32，写入数据量为10G

```bash
root@ceph-1:~# rbd bench mypool/data-img --io-type read --io-size 1M --io-pattern seq  --io-threads 32 --io-total 10G
bench  type read io_size 1048576 io_threads 32 bytes 10737418240 pattern sequential
  SEC       OPS   OPS/SEC   BYTES/SEC
    1      1088   1152.25   1.1 GiB/s
    8      1824   231.419   231 MiB/s
    9      2400   271.183   271 MiB/s
   10      3456   349.495   349 MiB/s
   11      4544   417.361   417 MiB/s
   12      5696     418.6   419 MiB/s
   13      6784   1004.04  1004 MiB/s
   14      7968    1112.7   1.1 GiB/s
   15      9120   1137.34   1.1 GiB/s
elapsed: 15   ops: 10240   ops/sec: 642.886   bytes/sec: 643 MiB/s
```

## 小文件IOPS测试
+ 4K随机写   
指定线程数为32，写入数据量为10G

```bash
root@ceph-1:~# rbd bench mypool/data-img --io-type write --io-size 4K --io-pattern rand  --io-threads 32 --io-total 10G
```

+ 4K随机读   
指定线程数为32，写入数据量为10G

```bash
root@ceph-1:~# rbd bench mypool/data-img --io-type read --io-size 4K --io-pattern rand  --io-threads 32 --io-total 10G
```

