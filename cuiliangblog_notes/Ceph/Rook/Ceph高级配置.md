# Ceph高级配置
[https://rook.io/docs/rook/latest-release/Storage-Configuration/Advanced/ceph-configuration/#deploying-a-second-cluster](https://rook.io/docs/rook/latest-release/Storage-Configuration/Advanced/ceph-configuration/#deploying-a-second-cluster)

# OSD 信息获取
获取 OSD 及其底层存储设备的信息，可以通过如下脚本实现：

```yaml
# cat osd.sh            
#!/bin/bash
OSD_PODS=$(kubectl get pods --all-namespaces -l \
    app=rook-ceph-osd,rook_cluster=rook-ceph -o jsonpath='{.items[*].metadata.name}')

# Find node and drive associations from OSD pods
for pod in $(echo ${OSD_PODS}); do
    echo "Pod:  ${pod}"
    echo "Node: $(kubectl -n rook-ceph get pod ${pod} -o jsonpath='{.spec.nodeName}')"
    kubectl -n rook-ceph exec ${pod} -c osd -- sh -c '\
  for i in /var/lib/ceph/osd/ceph-*; do
    [ -f ${i}/ready ] || continue
    echo -ne "-$(basename ${i}) "
    echo $(lsblk -n -o NAME,SIZE ${i}/block 2> /dev/null || \
    findmnt -n -v -o SOURCE,SIZE -T ${i}) $(cat ${i}/type)
  done | sort -V
  echo'
done

# sh osd.sh
Pod:  rook-ceph-osd-0-6c74d9b9d9-5fz84
Node: k8s-1
-ceph-0 sdb 100G bluestore

Pod:  rook-ceph-osd-1-64b7b7d55-zzl5j
Node: k8s-2
-ceph-1 sdb 100G bluestore

Pod:  rook-ceph-osd-2-65d6f8bdc7-99jgg
Node: k8s-3
-ceph-2 sdb 100G bluestore
```

# 配置 pool 参数
Ceph提供了调整pool的参数，即ceph osd pool set size|pg_num|pgp_num等参数，以及副本数量。 pool还有⼀个很重要的参数是PG数量，PG是place group的简写，和PGP⼀起代表 数据的分布情况，通过crush算法将PG分布到同步的OSD上，OSD上的PG如果分布过少的话可能会导致 数据的丢失，因此需要设定⼀个相对合理的数值，默认已经开启了“⾃动调整pg”的功能，如下  

```bash
bash-5.1$ ceph osd pool autoscale-status
POOL                          SIZE  TARGET SIZE  RATE  RAW CAPACITY   RATIO  TARGET RATIO  EFFECTIVE RATIO  BIAS  PG_NUM  NEW PG_NUM  AUTOSCALE  BULK   
.mgr                        452.0k                3.0        300.0G  0.0000                                  1.0       1              on         False  
k8s-rbd                      5515                 3.0        300.0G  0.0000                                  1.0      32              on         False  
k8sfs-metadata              628.0k                3.0        300.0G  0.0000                                  4.0      16              on         False  
k8sfs-replicated            20480                 3.0        300.0G  0.0000                                  1.0      32              on         False  
.rgw.root                   65536                 3.0        300.0G  0.0000                                  1.0       8              on         False  
k8s-rgw.rgw.meta            42367                 3.0        300.0G  0.0000                                  1.0       8              on         False  
k8s-rgw.rgw.buckets.index     965                 3.0        300.0G  0.0000                                  1.0       8              on         False  
k8s-rgw.rgw.buckets.non-ec      0                 3.0        300.0G  0.0000                                  1.0       8              on         False  
k8s-rgw.rgw.control             0                 3.0        300.0G  0.0000                                  1.0       8              on         False  
k8s-rgw.rgw.log             665.2k                3.0        300.0G  0.0000                                  1.0       8              on         False  
k8s-rgw.rgw.otp                 0                 3.0        300.0G  0.0000                                  1.0       8              on         False  
k8s-rgw.rgw.buckets.data        0                 1.5        300.0G  0.0000                                  1.0      32              on         False
```

 Ceph会根据数据的情况，⾃动调整的PG的的⼤⼩，⼀般⽽⾔⽣产中需要⼿动设定PG的⼤⼩，因此需要将其关闭  

```bash
bash-5.1$ ceph osd pool set k8s-rbd pg_autoscale_mode off
set pool 4 pg_autoscale_mode to off 
bash-5.1$ ceph osd pool get k8s-rbd pg_autoscale_mode
pg_autoscale_mode: off
```

关闭之后，则需要⼿动设定PG和PGP的数量 

```bash
bash-5.1$ ceph osd pool set k8s-rbd pg_num 32
bash-5.1$ ceph osd pool set k8s-rbd pgp_num 32
set pool 4 pgp_num to 32
bash-5.1$ ceph osd pool get k8s-rbd all
size: 3
min_size: 2
pg_num: 32
pgp_num: 32
crush_rule: k8s-rbd
hashpspool: true
nodelete: false
nopgchange: false
nosizechange: false
write_fadvise_dontneed: false
noscrub: false
nodeep-scrub: false
use_gmt_hitset: 1
fast_read: 0
pg_autoscale_mode: off
eio: false
bulk: false
```

# 调整 mon 参数
调整Ceph的参数⼀般有两种⽅式： 

+ 临时调整，通过config set的⽅式做调整，可以在线调整Ceph的参数，这种调整是临时有效 
+ 永久⽣效，调整ceph.conf配置⽂件，调整后需要重启各个组件进程  

例如创建pool的时候都会分配pg_num和pgp_num数量，这个值默认是32  

```bash
kubectl exec -it -n rook-ceph rook-ceph-mon-a-8fb49bdf-28lpc -c mon -- bash 
[root@k8s-3 ceph]# ceph --admin-daemon /var/run/ceph/ceph-mon.a.asok config show | grep pg_num
    "mgr_debug_aggressive_pg_num_changes": "false",
    "mgr_max_pg_num_change": "128",
    "mon_max_pool_pg_num": "65536",
    "mon_warn_on_pool_pg_num_not_power_of_two": "true",
    "osd_pool_default_pg_num": "32", # 默认pool的pg_num为32
```

## 临时调整
通过config set 方式临时调整osd_pool_default_pg_num 参数

```bash
# kubectl exec -it -n rook-ceph rook-ceph-tools-699dcdd8bb-98ndc -- bash
bash-5.1$ ceph config set global osd_pool_default_pg_num 16
```

验证

```bash
[root@k8s-3 ceph]# ceph --admin-daemon /var/run/ceph/ceph-mon.a.asok config show | grep pg_num
    "mgr_debug_aggressive_pg_num_changes": "false",
    "mgr_max_pg_num_change": "128",
    "mon_max_pool_pg_num": "65536",
    "mon_warn_on_pool_pg_num_not_power_of_two": "true",
    "osd_pool_default_pg_num": "16", # 默认pool的pg_num为16
```

# 调整Ceph 集群参数  
config set的⽅式是临时有效的，如果需要使配置永久⽣效需要修改ceph.conf配置⽂件，使配置能够永久⽣效，在rook中需要通过修改rook-config-override这个configmap实现配置的管理 

## 导出集群默认配置
```yaml
# kubectl -n rook-ceph get ConfigMap rook-config-override -o yaml
apiVersion: v1
data:
  config: ""
kind: ConfigMap
metadata:
  creationTimestamp: "2024-12-31T08:00:03Z"
  name: rook-config-override
  namespace: rook-ceph
  ownerReferences:
  - apiVersion: ceph.rook.io/v1
    blockOwnerDeletion: true
    controller: true
    kind: CephCluster
    name: rook-ceph
    uid: 9a5f8e21-2836-47e1-bfa7-606a14c055fb
  resourceVersion: "81960"
  uid: a8f33a08-9547-429a-a5e5-dc51c70c44dc
```

## 调整集群配置
```yaml
# cat rook-config-override.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
 name: rook-config-override
 namespace: rook-ceph
data:
 config: |
  [global]
  osd_pool_default_pg_num = 32
  osd crush update on start = false
  osd pool default size = 2                                                                                                                                                                                    
# kubectl apply -f rook-config-override.yaml              
configmap/rook-config-override configured
```

## 重启 mon
```bash
# kubectl delete pod -n rook-ceph rook-ceph-mon-a-8fb49bdf-28lpc rook-ceph-mon-b-75f6f4cd8d-cppcz 
pod "rook-ceph-mon-a-8fb49bdf-28lpc" deleted
pod "rook-ceph-mon-b-75f6f4cd8d-cppcz" deleted
```

## 验证
```bash
# kubectl exec -it -n rook-ceph rook-ceph-mon-a-8fb49bdf-kvc45 -c mon -- bash
[root@k8s-3 ceph]# ceph --admin-daemon /var/run/ceph/ceph-mon.a.asok config show | grep pg_num
    "mgr_debug_aggressive_pg_num_changes": "false",
    "mgr_max_pg_num_change": "128",
    "mon_max_pool_pg_num": "65536",
    "mon_warn_on_pool_pg_num_not_power_of_two": "true",
    "osd_pool_default_pg_num": "32",
```

# 组件重启
修改rook-config-override之后，容器中的configmap会⾃动去读区到configmap配置⽂件的内容 ， 但是读取之后其配置并未⽣效，如果需要使配置⽣效，需要将对应的组件做重启，包括MON，MGR， RGW，MDS，OSD等，重启的时候需要注意单次不要重启⼀个pods进程，确保pods启动完毕之后，结合ceph -s观察状态，待ceph状态正常之后再重启其他的进程

重启OSD需要特别注意，其涉及到数据的迁移，因此需要确保重启过程中ceph的状态为 active+clean才能继续下⼀步骤的重启，避免因为重启⽽导致数据⼤规模移动影响正常的业务  

## 重启注意事项
+ Mons：在重启每个 Mon Pod 之前，确保三个 Mon 都在线且健康，按 一次一个 的顺序依次重启。
+ Mgrs：这些 Pod 是无状态的，可以根据需要重启，但请注意，在重启期间 Ceph Dashboard 会中断。
+ OSDs：通过删除 OSD Pod 的方式来重启，每次只重启 一个，并在每次重启后运行 `ceph -s` 确认集群状态恢复为 “active/clean”。
+ RGW（RADOS Gateway）：这些 Pod 是无状态的，可以根据需要重启。
+ MDS（Metadata Server）：这些 Pod 是无状态的，可以根据需要重启。

# 常用调优参数
```yaml
# cat rook-config-override.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
 name: rook-config-override
 namespace: rook-ceph
data:
 config: |
  [global]
  osd_pool_default_pg_num = 32 # 新创建的 Pool 的默认PG，默认156
  osd crush update on start = false # OSD 是否在启动时自动更新 CRUSH map 的设备信息，默认true
  osd pool default size = 2 # 新创建的 Pool 的默认副本数，默认3
  mon_allow_pool_delete = true # 允许删除pool，默认false
  mon_max_pg_per_osd = 250 #每个osd上最多PG数量，超过则告警，默认200
  mon_osd_full_ratio = 0.95 #osd利⽤率达到95%时数据⽆法写⼊，默认0.95
  mon_osd_nearfull_ratio = 0.85 #接近写满时告警，默认0.85
  [osd]
  osd_recovery_op_priority = 1 #osd数据恢复时优先级，默认为3
  osd_recovery_max_active = 1 #osd同时恢复时pg的数量，默认是0
  osd_max_backfills = 1 #backfills数据填充的数量
  osd_recovery_max_chunk = 1048576 #恢复时数据块⼤⼩，默认8388608
  osd_scrub_begin_hour = 1 #scrub⼀致性校验开始的时间，默认为0
  osd_scrub_end_hour = 6 #scrub⼀致性校验结束的时间，默认为24
```

# 调整CRUSH结构  
crushmap是Ceph决定数据分布的⽅式，一般采⽤默认的crushmap即可，有些场景需要做调整，如：

+ 数据分布，如SSD+HDD融合环境，需要将SSD资源池和HDD资源池分开，给两种不同的业务混合使⽤ 
+ 权重分配，OSD默认会根据容量分配对应的weight，但数据不是绝对的平均，容量不平均的时候可以调整 
+ OSD亲和⼒，调整OSD数据主写的亲和力机制  

如某个OSD利⽤率过⾼，达到85%的时候会提示nearfull，这个时候需要扩容OSD到集群中，如果其他的 OSD利⽤率不⾼，则可以根据需要调整OSD的权重，触发数据的重新分布，如下： 

```yaml
# ceph osd crush reweight osd.3 0.8
```

调整之后，会⾃动的做数据的rebalance。

