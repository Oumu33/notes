# 集群维护

> 来源: Ceph
> 创建时间: 2024-12-01T17:44:27+08:00
> 更新时间: 2026-01-11T09:43:41.302628+08:00
> 阅读量: 78 | 点赞: 0

---

# 故障处理思路
## 查看集群状态
```plain
root@ceph-1:~# ceph -s
  cluster:
    id:     f8d1caa2-ad9c-11ef-a4a0-b375f80a1752
    health: HEALTH_WARN
            3 failed cephadm daemon(s)
            1/3 mons down, quorum ceph-1,ceph-2
            OSD count 0 < osd_pool_default_size 3

  services:
    mon: 3 daemons, quorum ceph-1,ceph-2 (age 11m), out of quorum: ceph-3
    mgr: ceph-1.ijhrsl(active, since 11m), standbys: ceph-2.wtyddl
    osd: 0 osds: 0 up, 0 in

  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   0 B used, 0 B / 0 B avail
    pgs:
```

从你提供的集群状态输出来看，Ceph 集群处于 `HEALTH_WARN` 状态，主要问题是：

1. 3 个 cephadm 守护进程失败：表示有 3 个 Ceph 守护进程无法正常运行。
2. 1 个 Monitor 节点宕机，当前 `quorum` 仅包含 `ceph-1` 和 `ceph-2`，`ceph-3` 不在 quorum 中，可能影响集群的健康性。
3. OSD 数量为 0，这意味着集群没有 OSD 节点，导致副本数无法满足 `osd_pool_default_size 3` 的要求。没有 OSD 的话，数据无法正常存储和恢复。

## 查看守护进程状态
```bash
root@ceph-1:~# ceph orch ps
NAME                  HOST    PORTS             STATUS        REFRESHED  AGE  MEM USE  MEM LIM  VERSION    IMAGE ID      CONTAINER ID  
alertmanager.ceph-1   ceph-1  *:9093,9094       error            5m ago   2d        -        -  <unknown>  <unknown>     <unknown>
ceph-exporter.ceph-1  ceph-1                    running (6m)     5m ago   2d    9.85M        -  18.2.4     2bc0b0f4375d  ee09de48a195
ceph-exporter.ceph-2  ceph-2                    running (6m)     6m ago   2d    13.5M        -  18.2.4     2bc0b0f4375d  0f0512332580
ceph-exporter.ceph-3  ceph-3                    running (6m)     6m ago   2d    9528k        -  18.2.4     2bc0b0f4375d  bf99027af1ca
crash.ceph-1          ceph-1                    running (6m)     5m ago   2d    10.8M        -  18.2.4     2bc0b0f4375d  6a97f6e7611e
crash.ceph-2          ceph-2                    running (6m)     6m ago   2d    16.5M        -  18.2.4     2bc0b0f4375d  48dda354ab9f
crash.ceph-3          ceph-3                    running (6m)     6m ago   2d    14.0M        -  18.2.4     2bc0b0f4375d  310d2b7cae45
grafana.ceph-1        ceph-1  *:3000            running (6m)     5m ago   2d     120M        -  9.4.7      954c08fa6188  dd5217fe82cf
mgr.ceph-1.xklufv     ceph-1  *:9283,8765,8443  running (6m)     5m ago   2d     466M        -  18.2.4     2bc0b0f4375d  b844f7cdcd17
mgr.ceph-3.yjdakp     ceph-3  *:8443,9283,8765  running (6m)     6m ago   2d     488M        -  18.2.4     2bc0b0f4375d  058adef5618a
mon.ceph-1            ceph-1                    running          5m ago   2d        -    2048M  <unknown>  <unknown>     <unknown>
mon.ceph-2            ceph-2                    running (6m)     6m ago   2d    41.0M    2048M  18.2.4     2bc0b0f4375d  57158cb4c5a1
mon.ceph-3            ceph-3                    running (6m)     6m ago   2d    30.5M    2048M  18.2.4     2bc0b0f4375d  ae1e928e3dff
node-exporter.ceph-1  ceph-1  *:9100            error            5m ago   2d        -        -  <unknown>  <unknown>     <unknown>
node-exporter.ceph-2  ceph-2  *:9100            running (6m)     6m ago   2d    9.96M        -  1.5.0      0da6a335fe13  0080b5c3272d
node-exporter.ceph-3  ceph-3  *:9100            unknown          6m ago   2d        -        -  <unknown>  <unknown>     <unknown>
osd.0                 ceph-1                    running (6m)     5m ago   2d    70.2M    4096M  18.2.4     2bc0b0f4375d  e884353bde88
osd.1                 ceph-2                    running (6m)     6m ago   2d    67.6M    4096M  18.2.4     2bc0b0f4375d  98503bbfba86
osd.2                 ceph-3                    running (6m)     6m ago   2d    70.2M    4096M  18.2.4     2bc0b0f4375d  3c611e82107b
prometheus.ceph-1     ceph-1  *:9095            unknown          5m ago   2d        -        -  <unknown>  <unknown>     <unknown>
```

## 重启守护进程
查看哪些 `cephadm` 守护进程失败，然后尝试重启或修复它们，可以使用以下命令重启：

```bash
ceph orch restart <daemon_name>
```

或者，如果守护进程故障严重，可能需要重新部署这些守护进程。

## 查看组件日志
```bash
root@ceph-1:/var/log/ceph/8e04b1c8-ad9f-11ef-a78d-07c031166f43# ls
ceph-client.ceph-exporter.ceph-1.log  ceph-osd.0.log  ceph-volume.log
```

## 服务日志查看
```plain
root@ceph-1:~# journalctl -u ceph-402d9800-afef-11ef-92d7-9fbbd69ceccd@osd.0.service
```

# 节流回填和恢复  
## 节流回填（Throttling Backfill）
当 Ceph 集群进行数据恢复或重平衡时，它会尝试将数据重新分布到不同的 OSD 上。在这个过程中，如果集群负载过高，可能会影响整体性能。因此，Ceph 会使用“节流”机制来限制回填过程的速率，以防止过度影响集群的其他操作。

### 主要参数
+ **osd_recovery_max_active**: 最大同时进行的恢复操作数（默认为 3）。它限制了同时恢复的对象数量，防止恢复过程占用过多资源。
+ **osd_recovery_op_priority**: 控制恢复操作的优先级，默认值为 5。数值越高，恢复操作的优先级越高。
+ **osd_max_backfills**: 最大允许并发的回填操作数（默认为 1）。回填是 Ceph 中数据从一个 OSD 迁移到另一个 OSD 的过程。
+ **osd_backfillfull_ratio** 和 **osd_backfillup_ratio**: 控制当 OSD 存储使用超过一定阈值时，是否启动节流回填的操作。

### 节流回填配置
可以通过调整这些配置参数来控制回填的速率和最大并发数。以下是一些相关的配置项：

```bash
# 设置最大并发回填操作数
ceph tell osd.* injectargs '--osd_max_backfills=3'

# 设置恢复操作的最大并发数
ceph tell osd.* injectargs '--osd_recovery_max_active=3'
```

这些设置有助于控制集群的负载，防止在恢复过程中占用过多的 I/O 带宽和计算资源。

## Ceph 恢复（Recovery）
恢复是 Ceph 在检测到数据丢失或副本不一致时，尝试将丢失的数据恢复到集群中的过程。通常是在以下情况发生时触发恢复：

+ **OSD 崩溃或故障**：如果某个 OSD 宕机且未能自动恢复，Ceph 会进行恢复操作，将丢失的副本恢复到其他 OSD。
+ **新增 OSD 或硬盘**：当新加入 OSD 时，Ceph 会根据 CRUSH 规则决定将哪些数据迁移到新 OSD 上。
+ **重新平衡**：当存储池或集群的状态发生变化时（例如副本数或 CRUSH 规则更改），需要通过恢复将数据重新分配。

### 恢复过程
恢复过程涉及将数据从正常副本转移到目标 OSD。这通常会在以下两种操作中进行：

+ **数据恢复（Recovery）**：当 Ceph 检测到丢失的数据或副本时，使用存储池中的其他副本进行恢复。
+ **回填（Backfill）**：在数据恢复之后，Ceph 会执行回填操作，将数据从一个 OSD 转移到另一个 OSD，确保数据分布满足 CRUSH 规则。

### 相关命令
+ **查看恢复状态**：你可以使用 `ceph status` 命令来查看集群的整体健康状态以及当前的恢复进度。

```bash
ceph status
```

+ **查看恢复进度**：你可以使用以下命令查看具体的恢复过程和恢复速度：

```plain
ceph osd recovery status
```

+ **查看 PG 恢复进度**：查看某个 Placement Group 的恢复状态。

```plain
ceph pg recovery_status <pg_id>
```

## 控制恢复速率与回填速率
Ceph 会动态调整恢复和回填的速率，以便在不对集群性能产生负面影响的情况下完成数据恢复。可以通过以下配置项控制恢复和回填的速率：

+ **osd_recovery_max_single_start**：每次恢复操作开始时，最大启动的对象数。
+ **osd_recovery_op_priority**：恢复操作的优先级。如果你希望恢复操作优先级较高，设置更高的值。
+ **osd_recovery_pause_interval**：恢复操作的暂停间隔。
+ **osd_recovery_delay**：恢复操作的延迟时间，用于控制操作的节奏。

### 配置例子
```bash
# 设置最大恢复操作数
ceph tell osd.* injectargs '--osd_recovery_max_active=5'

# 设置恢复操作的优先级
ceph tell osd.* injectargs '--osd_recovery_op_priority=7'

# 设置恢复操作的延迟
ceph tell osd.* injectargs '--osd_recovery_delay=10'
```

## 停止或暂停恢复与回填操作
如果你需要临时停止恢复或回填操作，可以使用以下命令：

+ **停止恢复操作**：

```plain
ceph osd stop-recovery
```

+ **暂停回填操作**：

```plain
ceph osd pause-backfill
```


