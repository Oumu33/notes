# ILM索引生命周期管理

> 来源: ELK Stack
> 创建时间: 2022-07-15T19:46:25+08:00
> 更新时间: 2026-01-11T09:26:26.987057+08:00
> 阅读量: 1292 | 点赞: 0

---

## 什么是索引生命周期管理
若是时序数据的索引，随着时间的推移，业务索引的数据量会越来越大。但，基于如下的因素：

+  集群的单个分片最大文档数上限：2 的 32 次幂减去 1（20亿左右）。 	
+  索引最佳实践官方建议：分片大小控制在30GB-50GB，若索引数据量无限增大，肯定会超过这个值。 	
+  索引大到一定程度，当索引出现健康问题，会导致真个集群核心业务不可用。 	
+  大索引恢复的时间要远比小索引恢复慢的多得多。 	
+  索引大之后，检索会很慢，写入和更新也会受到不同程度的影响。 	
+  某些业务场景，用户更关心最近3天、最近7天的业务数据，大索引会将全部历史数据汇集在一起，不利于这种场景的查询。 	

这种分阶段、有目标的操作和实现，我们称为索引生命周期管理。

## 不同阶段的功能点
![](https://via.placeholder.com/800x600?text=Image+9b2c9cb164974081)

## 索引生命周期管理前提
### 冷热集群架构
要使用ILM，需要首先配置冷热架构，三个节点规划如下：

| 节点 | 角色 | 角色配置 |
| --- | --- | --- |
| es-1 | hot | master, <font style="color:rgb(74, 74, 74);">data_content,data_</font>hot |
| es-2 | warm | <font style="color:rgb(74, 74, 74);">data_content </font>, ingest,data_warm |
| es-3 | cold | <font style="color:rgb(74, 74, 74);">data_content </font>, ingest,data_cold |


以日志数据为例，0-7天数据存放hot节点，7-15天数据存放warm节点，15天-30天数据存放clod节点，30天以上数据删除

### rollover 滚动索引
Rollover API解决的是以日期作为索引名称的索引大小不均衡的问题。

Rollover API对于日志类的数据非常有用，一般我们按天来对索引进行分割（数据量更大还能进一步拆分），没有Rollover之前，需要在程序里设置一个自动生成索引的模板。

```json
# 创建index别名，滚动索引后会生成多个index，可通过别名查询
PUT my-index-2022.07.21-000001
{
  "aliases": {
    "my-alias": {
      "is_write_index": true
    }
  }
}
# 批量插入5条数据测试
PUT my-alias/_bulk
{"index":{"_id":1}}
{"title":"testing 01"}
{"index":{"_id":2}}
{"title":"testing 02"}
{"index":{"_id":3}}
{"title":"testing 03"}
{"index":{"_id":4}}
{"title":"testing 04"}
{"index":{"_id":5}}
{"title":"testing 05"}
# 创建滚动索引触发规则
POST my-alias/_rollover
{
  "conditions": {
    "max_age": "7d", // 最长期限 7d，超过7天，索引会实现滚动。
    "max_docs": 5, // 最大文档数 5，超过 5个文档，索引会实现滚动（测试需要，设置的很小）。
    "max_primary_shard_size": "50gb" // 主分片最大存储容量 50GB，超过50GB，索引就会滚动。
  }
}
# 响应
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "old_index" : "my-index-2022.07.21-000001",
  "new_index" : "my-index-2022.07.21-000002",
  "rolled_over" : true,
  "dry_run" : false,
  "conditions" : {
    "[max_docs: 5]" : true,
    "[max_primary_shard_size: 50gb]" : false,
    "[max_age: 7d]" : false
  }
}
# 继续插入数据，满足文档超过5个的条件，出发滚动
PUT my-alias/_bulk
{"index":{"_id":6}}
{"title":"testing 06"}

# 检索数据验证滚动是否生效
{
  "took" : 755,
  "timed_out" : false,
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 6,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      ……
      {
        "_index" : "my-index-2022.07.21-000001",
        "_type" : "_doc",
        "_id" : "5",
        "_score" : 1.0,
        "_source" : {
          "title" : "testing 05"
        }
      },
      {
        "_index" : "my-index-2022.07.21-000002",
        "_type" : "_doc",
        "_id" : "6",
        "_score" : 1.0,
        "_source" : {
          "title" : "testing 06"
        }
      }
    ]
  }
}

```

_id 为 6 的数据索引名称变成了：my-index-2021.05.30-000002，实现了 后缀 id 自增。

设置的滚动索引触发的三个条件是或的关系，满足其中一个，索引就会滚动。

### shrink索引压缩
elasticsearch 索引的 shard 数是固定的，设置好了之后不能修改，如果发现 shard 太多或者太少的问题，之前如果要设置 Elasticsearch 的分片数，只能在创建索引的时候设置好，并且数据进来了之后就不能进行修改，如果要修改，只能重建索引。

现在有了 Shrink 接口，它可将分片数进行收缩成它的因数，如之前你是 15 个分片，你可以收缩成 5 个或者 3 个又或者 1 个，如果是素数例如7个分片，只能缩小为1个。那么我们就可以想象成这样一种场景，在写入压力非常大的收集阶段，设置足够多的索引，充分利用 shard 的并行写能力，索引写完之后收缩成更少的 shard，提高查询性能。

压缩索引的本质：在索引只读等三个条件的前提下，减少索引的主分片数。

Shrink原理

首先，它创建一个新的目标索引，其定义与源索引相同，但主分片数量较少。

然后，它将源索引中的段硬链接到目标索引。（如果文件系统不支持硬链接，则会将所有段复制到新索引中，这是一个更耗时的过程。）

最后，它恢复了目标索引，好像它是一个刚重新打开的封闭索引。

+ 数据准备

```json
# 新建index名称为kibana_sample_data_logs_ext，分片数为5
PUT kibana_sample_data_logs_ext
{
  "settings": {
    "number_of_shards": 5
  }
}
# 执行reindex，拷贝kibana_sample_data_logs数据至kibana_sample_data_logs_ext
POST _reindex
{
  "source": {
    "index": "kibana_sample_data_logs"
  },
  "dest": {
    "index": "kibana_sample_data_logs_ext"
  }
}
```

![](https://via.placeholder.com/800x600?text=Image+5e2f6b2b475eccd7)

+ 准备压缩

```json
# shrink 压缩之前的三个必要条件
PUT kibana_sample_data_logs_ext/_settings
{
  "settings": {
    "index.number_of_replicas": 0, // 副本设置为 0
    "index.routing.allocation.require._name": "node-2", // 分片数据要求都集中到一个独立的节点
    "index.blocks.write": true // 索引数据只读                            
  }
}
```

![](https://via.placeholder.com/800x600?text=Image+6a16141c11f369af)

+ 执行压缩

```json
POST kibana_sample_data_logs_ext/_shrink/kibana_sample_data_logs_shrink
{
  "settings": {
    "index.number_of_replicas": 0,
    "index.number_of_shards": 1,
    "index.codec": "best_compression"
  },
  "aliases": {
    "kibana_sample_data_logs_alias": {}
  }
}
```

查看kibana_sample_data_logs_shrink分片信息

![](https://via.placeholder.com/800x600?text=Image+3a770649413346d9)

### frozen冷冻索引
为高效检索，核心业务索引都会保持在内存中，意味着内存使用率会变得很高。

对于一些非业务必须、非密集访问的某些索引，可以考虑释放内存，仅磁盘存储，必要的时候再还原检索。

这时候，就会用到 Frozen 冷冻索引。除了在内存中维护其元数据，冻结索引在集群上几乎没有开销，并且冷冻索引是只读的。

```json
# 检索测试
GET kibana_sample_data_logs/_search
{
  "query": {
    "match": {
      "bytes": 0
    }
  }
}
# 冷冻索引
POST kibana_sample_data_logs_shrink/_freeze
# 插入数据测试，返回403无法写入
POST kibana_sample_data_logs_shrink/_doc/1
{
  "test":"123"
}
# 搜索测试，不报错，但不返回具体结果
GET kibana_sample_data_logs_shrink/_search
{
  "query": {
    "match": {
      "bytes": 0
    }
  }
}
# 检索响应
{
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 0,
    "successful" : 0,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 0,
      "relation" : "eq"
    },
    "max_score" : 0.0,
    "hits" : [ ]
  }
}
# 解除冷冻
POST kibana_sample_data_logs_shrink/_unfreeze

# 检索插入测试，可读可写
```

综合上述拆解分析可知：

有了：冷热集群架构，集群的不同节点有了明确的角色之分，冷热数据得以物理隔离，SSD 固态盘使用效率会更高。

有了：rollover 滚动索引，索引可以基于文档个数、时间、占用磁盘容量滚动升级，实现了索引的动态变化。

有了：Shrink 压缩索引、Frozen 冷冻索引，索引可以物理层面压缩、冷冻，分别释放了磁盘空间和内存空间，提高了集群的可用性。

除此之外，还有：Force merge 段合并、Delete 索引数据删除等操作，索引的“生、老、病、死”的全生命周期的

更迭，已然有了助推器。

## ILM实战
### 注意事项
以日志数据为例，0-7天数据存放hot节点，7-15天数据存放warm节点，15天-30天数据存放clod节点，30天以上数据删除

需要注意min_age是index写入时间，但是如果hot阶段配置了rollover，那么rollover之后索引的age会清0，计算min_age时需要减去rollover的时间

+ 如果在hot没有配置rollover，hot的min_age=0ms，warm的min_age=7d，cold的min_age=15d，delete的min_age=30d
+ 如果在hot阶段配置了rollover参数，设置max_age=7d，warm的min_age=0d，cold的min_age=8d，delete的min_age=23d

因此，在考试的时候要看清楚，题目要不要设置rollover

### 各生命周期 Actions 设定
### Hot 阶段
+ 基于：max_age=3天、最大文档数为5、最大size为：50gb rollover 滚动索引。 	
+ 设置优先级为：100（值越大，优先级越高）。 	

### Warm 阶段
+ 实现段合并，max_num_segments 设置为1. 	
+ 副本设置为 0。 	
+ 3-7天数据迁移到：warm 节点。 	
+ 优先级设置为：50。 	

### Cold 阶段
+  冷冻索引 	
+  7-30天数据迁移到冷节点 	

### Delete 阶段
+  30天以上数据删除索引 	

### 关于触发滚动的条件： 	 	
+  Hot 阶段的触发条件：手动创建第一个满足模板要求的索引。 	
+  其余阶段触发条件：min_age索引自创建后的时间。 <font style="color:rgb(74, 74, 74);">在索引生命周期管理检查min_age并过渡到下一个阶段之前，前一个阶段的操作必须完成。</font>

## DSL 索引生命周期管理
### 操作实践
```json
# 默认10分钟检查是否满足 rollover 的周期频率值，改为1s，便于演示
PUT _cluster/settings
{
 "persistent": {
 "indices.lifecycle.poll_interval": "1s"
 }
}
# 定义名称为my_custom_policy_filter的生命周期策略
PUT _ilm/policy/my_custom_policy_filter
{
  "policy": {
    "phases": {
      "hot": { // hot节点配置
        "actions": {
          "rollover": { // 滚动索引触发条件
            "max_age": "3d", // 超过3天，索引会实现滚动。 
            "max_docs": 5, // 超过 5个文档，索引会实现滚动
            "max_size": "50gb" // 主分片最大存储容量 50GB，超过50GB，索引就会滚动
          },
          "set_priority": {
            "priority": 100 // 优先级100
          }
        }
      },
      "warm": { // warm节点配置
        "min_age": "3d", // 索引创建3d后，进入该阶段
        "actions": {
          "forcemerge": {
            "max_num_segments": 1 // 指定段数目最大为1
          },
          "allocate": {
            "require": {
              "box_type": "warm" // 数据迁移至warm节点
            },
            "number_of_replicas": 0 // 副本数改为0
          },
          "set_priority": {
            "priority": 50 // 有限级50
          }
        }
      },
      "cold": {
        "min_age": "7d", // 索引创建7天后，进入该阶段
        "actions": {
          "allocate": {
            "require": {
              "box_type": "cold" // 移至cold节点
            }
          },
          "freeze": {} // 冷冻索引
        }
      },
      "delete": {
        "min_age": "30d", // 索引创建30d后，进入该阶段 
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
# 创建模板，关联配置的ilm_policy
PUT _index_template/timeseries_template
{
  "index_patterns": ["timeseries-*"],                 
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 0,
      "index.lifecycle.name": "my_custom_policy_filter",      
      "index.lifecycle.rollover_alias": "timeseries",
      "index.routing.allocation.require.box_type": "hot"
    }
  }
}
# 创建起始索引别名
PUT timeseries-000001
{
  "aliases": {
    "timeseries": {
      "is_write_index": true
    }
  }
}
# 插入数据
PUT timeseries/_bulk
{"index":{"_id":1}}
{"title":"testing 01"}
{"index":{"_id":2}}
{"title":"testing 02"}
{"index":{"_id":3}}
{"title":"testing 03"}
{"index":{"_id":4}}
{"title":"testing 04"}
# 临界值（会滚动）
PUT timeseries/_bulk
{"index":{"_id":5}}
{"title":"testing 05"}
# 下一个索引数据写入
PUT timeseries/_bulk
{"index":{"_id":6}}
{"title":"testing 06"}
```

### 步骤总结
+  第一步：创建生周期 policy。 	
+  第二步：创建索引模板，模板中关联 policy 和别名。 	
+  第三步：创建符合模板的起始索引，并插入数据。 	
+  第四步: 索引基于配置的 ilm 滚动。 	



## kibana管理索引生命周期
Stack Management**<font style="color:rgb(52, 55, 65);">——>Index Lifecycle Management</font>**

### <font style="color:rgb(52, 55, 65);">hot设置</font>
基于：max_age=3天、最大文档数为100、最大size为：5gb rollover 滚动索引。 	

设置优先级为：100（值越大，优先级越高）。 	

![](https://via.placeholder.com/800x600?text=Image+8cc3041d54830f98)

### <font style="color:rgb(26, 28, 33);">Warm设置</font>
![](https://via.placeholder.com/800x600?text=Image+a0f75c9daeb4e652)

### Cold设置
![](https://via.placeholder.com/800x600?text=Image+d378258d8acc2da3)

### Delete设置
![](https://via.placeholder.com/800x600?text=Image+3b47aab44c7590bb)

### 创建模板
![](https://via.placeholder.com/800x600?text=Image+6fcb86309c6672e9)

### 关联模板![](https://via.placeholder.com/800x600?text=Image+be0498111c1a7d4f)
## ILM配置排查
```json
GET index_name/_ilm/explain
```

## 参考文档
es 索引生命周期管理：[https://www.elastic.](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-lifecycle-management.html)

[co/guide/en/elasticsearch/reference/7.13/index-lifecycle-management.html](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-lifecycle-management.html)

es ilm api设置策略：[https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-index-lifecycle.html](https://www.elastic.co/guide/en/elasticsearch/reference/7.13/ilm-index-lifecycle.html)




