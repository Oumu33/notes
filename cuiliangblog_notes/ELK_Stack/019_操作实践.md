# 操作实践
## mapping创建
+ 创建索引 movies ，并包含以下字段

| 字段名称 | 类型 | 要求 |
| --- | --- | --- |
| name | text | 包含 keyword 类型的子字段：raw |
| brief | text | 分词器使用english |
| details | object | publish_date：date 类型的，格式为 "yyyy-MM-dd"<br/>duration：长整型<br/>locations：geo_point 类型 |
| actors | nested object | name：text 类型<br/>nation：keyword 类型 |


+ 答案

```json
PUT movies
{
  "mappings": {
    "properties": {
      "name":{
        "type": "text",
        "fields":{
          "raw": {
            "type": "keyword"
          }
        }
      },
      "brief":{
        "type": "text",
        "analyzer": "english"
      },
      "details":{
        "type": "object",
        "properties": {
          "publish_date":{
            "type":"date",
            "format":"yyyy-MM-dd"
          },
          "duration":{
            "type":"long"
          },
          "locations":{
            "type":"geo_point"
          }
        }
      },
      "actors":{
        "type": "nested",
        "properties": {
          "name": {
            "type": "text"
          },
          "nation": {
            "type": "keyword"
          }
        }
      }
    }
  }
}
```

## analyze API使用
使用 _analyze API 测试以下文本，并写出测试命令

```json
This is a brief of the movie!
```

1. 使用 standard 分词器测试
2. 使用 movies 中的 brief 字段进行测试
3. 按以下配置测试
+ 使用 **standard** tokenizer
+ 使用 **lowercase** token filter
+ 使用 **html_strip** character filter

答案

```json
# 使用 standard 分词器测试
POST /_analyze
{
  "analyzer": "standard",
  "text": "This is a brief of the movie!"
}
# 使用 movies 中的 brief 字段进行测试
POST movies/_analyze
{
  "analyzer": "standard",
  "field": "brief", 
  "text": "This is a brief of the movie!"
}
# 按以下自定义分词器测试
POST /_analyze
{
  "char_filter": ["html_strip"],
  "tokenizer":"standard",
  "filter": ["lowercase"],
  "text": "This is a brief of the movie!"
}
```

## 自定义分词器
导入数据到 blogs 索引:

```json
curl -s https://puxiang-public-packages.s3.cn-north-1.amazonaws.com.cn/elastictalk/cp3/blogs.json | curl -XPOST "localhost:9200/_bulk?pretty" \
-H "Content-Type: application/json" \
--data-binary @-
```

添加 blogs_analyzed 索引并设置 mapping，为 title 和 content 字段设置自定义分词器 my_analyzer，满足以下需求 ：

+ 要求在 content 中搜索 C++ 时，可以搜索到 c++ 和 C++ 的内容
+ 在 title 中搜索 IT 时，要求只能搜索到大写的 IT，不能包含 it
+ 在分词阶段 lowercase 所有文本
+ 在分词阶段移除所有默认的 stop words
+ 在分词阶段同时移除这些词语：can, we, our, you, your, all  
测试分词效果：

```json
# 导入数据到 blogs_analyze
POST _reindex
{
  "source": {
    "index": "blogs"
  },
  "dest": {
    "index": "blogs_analyzed"
  }
}

# 搜索 C++
GET blogs_analyzed/_search
{
  "query": {
    "match": {
      "content.my_analyzer": "c++"
    }
  }
}

# 搜索 IT
GET blogs_analyzed/_search
{
  "query": {
    "match": {
      "title.my_analyzer": "IT"
    }
  }
}
```

答案

```json
PUT blogs_analyzed
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "fields": {
          "my_analyzer": {
            "type": "text",
            "analyzer": "my_analyzer"
          }
        }
      },
      "content": {
        "type": "text",
        "fields": {
          "my_analyzer": {
            "type": "text",
            "analyzer": "my_analyzer"
          }
        }
      }
    }
  },
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "char_filter": "my_char_filter",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "stop",
            "my_filter"
          ]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "mapping",
          "mappings": [
            "c++ => cpp",
            "C++ => cpp",
            "IT => _IT_"
          ]
        }
      },
      "filter": {
        "my_filter": {
          "type": "stop",
          "stopwords": [
            "can",
            "we",
            "our",
            "you",
            "your",
            "all"
          ]
        }
      }
    }
  }
}
```




