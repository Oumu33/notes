# 集群写入性能优化

> 来源: ELK Stack
> 创建时间: 2022-12-26T22:32:17+08:00
> 更新时间: 2026-01-11T09:26:47.475412+08:00
> 阅读量: 1115 | 点赞: 0

---

<font style="color:rgba(0, 0, 0, 0.9);">  
</font><font style="color:rgb(62, 62, 62);">写入的目标在于增大写入的吞吐量，这里主要从两个方面进行优化：</font>

# <font style="color:rgb(62, 62, 62);">客户端</font>
+ <font style="color:rgb(62, 62, 62);">通过压测确定每次写入的文档数量。一般情况：</font><font style="color:rgb(62, 62, 62);">单个bulk请求数据两不要太大，官方建议5-15mb</font><font style="color:rgb(62, 62, 62);">写入请求超时时间建议60s以上</font><font style="color:rgb(62, 62, 62);">写入尽量不要一直写入同一节点，轮询达到不同节点。</font>
+ <font style="color:rgb(62, 62, 62);">进行多线程写入，最好的情况时动态调整，如果http429，此时可以少写入点，不是可以多写点</font>
+ <font style="color:rgb(62, 62, 62);">写入数据不指定_id，让ES自动产生当用户显示指定id写入数据时，ES会先发起查询来确定index中是否已经有相同id的doc存在，若有则先删除原有doc再写入新doc。这样每次写入时，ES都会耗费一定的资源做查询。如果用户写入数据时不指定doc，ES则通过内部算法产生一个随机的id，并且保证id的唯一性，这样就可以跳过前面查询id的步骤，提高写入效率。</font>

# <font style="color:rgb(62, 62, 62);">server</font>
<font style="color:rgb(62, 62, 62);">总体目标尽可能压榨服务器资源，提高吞吐量</font>

+ <font style="color:rgb(62, 62, 62);">使用好的硬件，观察cpu、ioblock、内存是否有瓶颈。</font>
+ <font style="color:rgb(62, 62, 62);">观察jvm堆栈，垃圾回收情况是否存在耗时较长的gc。</font>
+ <font style="color:rgb(62, 62, 62);">观察写入的分配和节点是否负载均衡。</font>
+ <font style="color:rgb(62, 62, 62);">调整bulk线程池和队列的大小，一般不用调整，它是根据现有核数和内存自动算出来的，酌情调整。</font><font style="color:rgb(62, 62, 62);">一般线程数配置为CPU核心数+1，队列也不要太大，否则gc比较频繁。</font>
+ <font style="color:rgb(62, 62, 62);">可靠性要求不高，可以副本设置为0。</font>
+ <font style="color:rgb(62, 62, 62);">磁盘io肯定没有内存快，可以在允许的情况refresh调整间隔大一点。</font>
+ <font style="color:rgb(62, 62, 62);">flush阈值适当调大、落盘异步化、flush频率调高。</font><font style="color:rgb(62, 62, 62);">这些都能减少写入资源的占用，提升写入吞吐能力。</font><font style="color:rgb(62, 62, 62);">但是对容灾能力有损害。</font>
+ <font style="color:rgb(62, 62, 62);">索引设置优化。</font>
+ <font style="color:rgb(62, 62, 62);">减少不必要的分词，从而降低cpu和磁盘的开销。</font>
+ <font style="color:rgb(62, 62, 62);">只需要聚合不需要搜索，index设置成false不需要算分，可以将norms设置成false</font>
+ <font style="color:rgb(62, 62, 62);">不要对字符串使用默认的dynmic mapping。</font><font style="color:rgb(62, 62, 62);">会自动分词产生不必要的开销。</font>
+ <font style="color:rgb(62, 62, 62);">index_options控制在创建倒排索引时，哪些内容会被条件到倒排索引中，只添加有用的，这样能很大减少cpu的开销。</font>
+ <font style="color:rgb(62, 62, 62);">关闭_source，减少io操作。</font><font style="color:rgb(62, 62, 62);">但是source字段用来存储文档的原始信息，如果我们以后可能reindex，那就必须要有这个字段。</font>
+ <font style="color:rgb(62, 62, 62);">设置30s refresh，降低lucene生成频次，资源占用降低提升写入性能，但是损耗实时性。</font>
+ <font style="color:rgb(62, 62, 62);">total_shards_per_node控制分片集中到某一节点，避免热点问题。</font>
+ <font style="color:rgb(62, 62, 62);">translong落盘异步化，提升性能，损耗灾备能力。</font>
+ <font style="color:rgb(62, 62, 62);">dynamic设置false，避免生成多余的分词字段，需要自行确定映射。</font>
+ <font style="color:rgb(62, 62, 62);">merge并发控制。</font>

# <font style="color:rgb(62, 62, 62);">merge</font>
+ <font style="color:rgb(62, 62, 62);">ES的一个index由多个shard组成，而一个shard其实就是一个Lucene的index，它又由多个segment组成，且Lucene会不断地把一些小的segment合并成一个大的segment，这个过程被称为merge。我们可以通过调整并发度来减少这一步占用的资源操作。</font>

```plain
index.merge.scheduler.max_thread_count
```

<font style="color:rgb(62, 62, 62);">这里可以针对myindex索引优化的示例：</font>

```json
PUT myindex 
{
    "settings": {
        "index" :{
            "refresh_interval" : "30s",
            "number_of_shards" :"2"
        },
        "routing": {
            "allocation": {
                "total_shards_per_node" :"3"
            }
        },
        "translog" :{
            "sync_interval" : "30s",
            "durability" : "async"
        },
        "number_of_replicas" : 0
    }
    "mappings": {
        "dynamic" : false,
        "properties" :{}
    }
}
```


